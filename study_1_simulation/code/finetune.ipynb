{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805c8b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import multiprocessing as mp\n",
    "import pickle \n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from imports import*\n",
    "from utils import *\n",
    "from logistic_regression import *\n",
    "from rnn import *\n",
    "\n",
    "from hybrid_sim import *\n",
    "from hybrid_fit import *\n",
    "from hybrid_predict import *\n",
    "\n",
    "from habit_sim import *\n",
    "from habit_fit import *\n",
    "from habit_predict import *\n",
    "\n",
    "from kdh_sim import *\n",
    "from kdh_fit import *\n",
    "from kdh_predict import *\n",
    "\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4a4df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num of agent\n",
    "num_of_agents = 200 # 200\n",
    "\n",
    "# num of block\n",
    "num_of_block = 2\n",
    "\n",
    "# num of trials \n",
    "num_of_trials = 200\n",
    "\n",
    "# for cross valdation \n",
    "array = np.arange(num_of_block)\n",
    "cv = [np.roll(array,i) for i in range(num_of_block)]\n",
    "cv = np.array(cv)\n",
    "\n",
    "models = {\n",
    "\n",
    "    'hybrid':[ configuration_parameters_hybrid,\n",
    "               hybrid_sim,\n",
    "               hybrid_fit,\n",
    "               hybrid_predict],\n",
    "    \n",
    "    'habit':[  configuration_parameters_habit,\n",
    "               habit_sim,\n",
    "               habit_fit,\n",
    "               habit_predict],\n",
    "    \n",
    "    'kdh':  [  configuration_parameters_kdh,\n",
    "               kdh_sim,\n",
    "               kdh_fit,\n",
    "               kdh_predict]\n",
    "}\n",
    "\n",
    "\n",
    "def bce(y_hat,y_true):\n",
    "    eps = 1e-7\n",
    "    return -np.sum( y_true*np.log(y_hat+eps) + (1-y_true)*np.log(1-y_hat+eps) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3d57fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim\n",
    "for m in models:\n",
    "    print(f'Model {m}')\n",
    "    \n",
    "    data_per_agent = []\n",
    "    parameters = []\n",
    "\n",
    "    for agent in tqdm(range(num_of_agents)):\n",
    "        param = models[m][0]()\n",
    "        parameters.append(param)\n",
    "        \n",
    "        data = []\n",
    "        for i in range(num_of_block):\n",
    "            # create rewards probs \n",
    "            reward_probs = create_rndwlk(4,num_of_trials)\n",
    "            df = models[m][1](\n",
    "                            param,\n",
    "                            num_of_trials,\n",
    "                            reward_probs\n",
    "            ) \n",
    "            data.append(df)\n",
    "        data_per_agent.append(data)\n",
    "\n",
    "    df = pd.DataFrame(parameters)\n",
    "    \n",
    "    for agent in range(num_of_agents):\n",
    "        for block in range(num_of_block):\n",
    "            data_per_agent[agent][block].to_csv(f'../data_finetune/{m}/{m}_agent_{agent}_sim_{block}.csv',index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af18874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload data\n",
    "all_data = [] \n",
    "for sim in range(num_of_block):\n",
    "    data_per_block = []\n",
    "    for m in tqdm(models): \n",
    "        for agent in range(num_of_agents):\n",
    "            data_per_block.append((pd.read_csv(f'../data_finetune/{m}/{m}_agent_{agent}_sim_{sim}.csv')))\n",
    "    all_data.append(data_per_block)\n",
    "    \n",
    "block_0 = all_data[0]\n",
    "block_1 = all_data[1]\n",
    "\n",
    "random.shuffle(block_0)\n",
    "random.shuffle(block_1)\n",
    "\n",
    "all_blocks = [block_0,block_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e649eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_pre(net, train_loader, val_loader , epochs, lr):\n",
    "        \n",
    "    train_loss, train_ll = np.zeros(epochs), np.zeros(epochs)\n",
    "    val_loss ,val_ll = np.zeros(epochs), np.zeros(epochs)\n",
    "    min_loss_v = 100\n",
    "\n",
    "    # move net to GPU\n",
    "    net.to(device)\n",
    "    # Use Adam optimizer\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr) \n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    # Loop over epochs\n",
    "    for i in tqdm(range(epochs)):\n",
    "        \n",
    "        # Loop over training batches\n",
    "        running_loss_tr = []\n",
    "        for j,(X_train,y_train) in enumerate(train_loader):\n",
    "            \n",
    "            # move to GPU\n",
    "            X_train , y_train = X_train.to(device), y_train.to(device)\n",
    "            # reshape to 1 X batch_size X input_size\n",
    "            X_train = X_train.reshape(1,X_train.shape[0], INPUT_SIZE)\n",
    "            # zero the gradient buffers\n",
    "            optimizer.zero_grad() \n",
    "            out, hn = net(X_train)\n",
    "            # Reshape to (SeqLen x Batch, OutputSize)\n",
    "            out = out.view(-1, OUTPUT_SIZE)\n",
    "            loss = criterion(out, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step() # Does the update\n",
    "            running_loss_tr.append(loss.item())\n",
    "            \n",
    "        train_loss[i], train_ll[i] = eval_net(net, train_loader)\n",
    "        val_loss[i], val_ll[i] = eval_net(net, val_loader)\n",
    "        \n",
    "        if val_loss[i] <= min_loss_v:\n",
    "            checkpoint = {'epoch':i+1,'model_state':net.state_dict(),\n",
    "                          'optim_state':optimizer.state_dict(),'loss':val_loss[i]}\n",
    "            torch.save(checkpoint,f'rnn_finetune_5_200.pth')\n",
    "            min_loss_v = val_loss[i]\n",
    "        \n",
    "        print('train loss: ', train_loss[i])\n",
    "        print('val loss: ', val_loss[i])\n",
    "        net.train()\n",
    "\n",
    "    return net, train_loss , train_ll , val_loss, val_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9af21c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.concat(all_blocks[0]).reset_index()\n",
    "df_val = pd.concat(all_blocks[1]).reset_index()\n",
    "\n",
    "INPUT_SIZE = 5\n",
    "OUTPUT_SIZE = 2\n",
    "LERANING_RATE = 0.001\n",
    "\n",
    "hidden_size = 5\n",
    "num_layers = 1\n",
    "epochs = 500\n",
    "\n",
    "train_data = behavior_dataset(df_train)\n",
    "val_data = behavior_dataset(df_val)\n",
    "\n",
    "train_loader = DataLoader(train_data,shuffle=False, batch_size=1_000)\n",
    "val_loader = DataLoader(val_data,shuffle=False, batch_size=1_000)\n",
    "\n",
    "rnn = GRU_NN(INPUT_SIZE, hidden_size, num_layers, OUTPUT_SIZE)\n",
    "rnn, train_loss, train_ll, val_loss, val_ll, = train_model_pre(rnn,\n",
    "                                                            train_loader,\n",
    "                                                            val_loader,\n",
    "                                                            epochs=epochs,\n",
    "                                                            lr=LERANING_RATE) \n",
    "\n",
    "\n",
    "\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03fc4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num of agent\n",
    "num_of_agents = 100\n",
    "\n",
    "# num of block\n",
    "num_of_block = 3\n",
    "\n",
    "# num of trials \n",
    "num_of_trials = 200\n",
    "\n",
    "# for cross valdation \n",
    "array = np.arange(num_of_block)\n",
    "cv = [np.roll(array,i) for i in range(num_of_block)]\n",
    "cv = np.array(cv)\n",
    "\n",
    "all_data = [] \n",
    "for sim in range(num_of_block):\n",
    "    data_per_block = []\n",
    "    for m in tqdm(models): \n",
    "        for agent in range(num_of_agents):\n",
    "            data_per_block.append((pd.read_csv(f'../data/{m}/{m}_agent_{agent}_sim_{sim}.csv')))\n",
    "    all_data.append(data_per_block)\n",
    "    \n",
    "block_0 = all_data[0]\n",
    "block_1 = all_data[1]\n",
    "block_2 = all_data[2]\n",
    "\n",
    "all_blocks = [block_0,block_1,block_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb58701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = num_of_agents*3 # 3 models\n",
    "\n",
    "INPUT_SIZE = 5\n",
    "OUTPUT_SIZE = 2\n",
    "LERANING_RATE = 0.001\n",
    "\n",
    "hidden_size = 5\n",
    "num_layers = 1\n",
    "epochs = 200\n",
    "\n",
    "loss_train, loss_val, loss_test  = [], [], []\n",
    "ll_train, ll_val, ll_test = [], [], []\n",
    "\n",
    "for n in tqdm(range(N)):\n",
    "    for train, val, test in cv:\n",
    "\n",
    "        train_data = behavior_dataset(all_blocks[train][n])\n",
    "        val_data = behavior_dataset(all_blocks[val][n])\n",
    "        test_data = behavior_dataset(all_blocks[test][n])\n",
    "\n",
    "        train_loader = DataLoader(train_data,shuffle=False,batch_size=len(train_data))\n",
    "        val_loader = DataLoader(val_data,shuffle=False,batch_size=len(val_data))\n",
    "        test_loader = DataLoader(test_data,shuffle=False,batch_size=len(test_data))\n",
    "        \n",
    "        load = torch.load(f'rnn_finetune_5_200.pth')\n",
    "        model = GRU_NN(INPUT_SIZE, hidden_size, num_layers, OUTPUT_SIZE)\n",
    "        model.load_state_dict(load['model_state'])\n",
    "        \n",
    "        _, train_loss, train_ll, val_loss, val_ll, test_loss, test_ll = train_model(model,\n",
    "                                                                                train_loader,\n",
    "                                                                                val_loader,\n",
    "                                                                                test_loader,\n",
    "                                                                                epochs=epochs,\n",
    "                                                                                lr=LERANING_RATE) \n",
    "                                                                                                                                       \n",
    "        loss_train.append(train_loss)\n",
    "        loss_val.append(val_loss)\n",
    "        loss_test.append(test_loss)\n",
    "        \n",
    "        ll_train.append(train_ll)\n",
    "        ll_val.append(val_ll)\n",
    "        ll_test.append(test_ll)\n",
    "        \n",
    "    print('Done agent',n)\n",
    "    \n",
    "    \n",
    "with open('../results_finetune/loss_train.pickle', 'wb') as handle:\n",
    "    pickle.dump(loss_train, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('../results_finetune/loss_val.pickle', 'wb') as handle:\n",
    "    pickle.dump(loss_val, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('../results_finetune/loss_test.pickle', 'wb') as handle:\n",
    "    pickle.dump(loss_test, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('../results_finetune/ll_train.pickle', 'wb') as handle:\n",
    "    pickle.dump(ll_train, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('../results_finetune/ll_val.pickle', 'wb') as handle:\n",
    "    pickle.dump(ll_val, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('../results_finetune/ll_test.pickle', 'wb') as handle:\n",
    "    pickle.dump(ll_test, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
