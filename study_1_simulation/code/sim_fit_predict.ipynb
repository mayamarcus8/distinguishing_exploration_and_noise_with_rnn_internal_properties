{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "805c8b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import multiprocessing as mp\n",
    "import pickle \n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from imports import*\n",
    "from utils import *\n",
    "from logistic_regression import *\n",
    "from rnn import *\n",
    "\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd4a4df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num of agent\n",
    "num_of_agents = 40\n",
    "\n",
    "# num of block\n",
    "num_of_block = 3\n",
    "\n",
    "# num of trials \n",
    "num_of_trials = 200\n",
    "\n",
    "# for cross valdation \n",
    "array = np.arange(num_of_block)\n",
    "cv = [np.roll(array,i) for i in range(num_of_block)]\n",
    "cv = np.array(cv)\n",
    "\n",
    "\n",
    "def bce(y_hat,y_true):\n",
    "    eps = 1e-7\n",
    "    return -np.sum( y_true*np.log(y_hat+eps) + (1-y_true)*np.log(1-y_hat+eps) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0af18874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload data\n",
    "def upload_data(num_of_block,num_of_agents,model):\n",
    "    all_data = [] \n",
    "    for sim in range(1,num_of_block+1):\n",
    "        data_per_block = []\n",
    "        for agent in range(1,num_of_agents+1):\n",
    "            data_per_block.append((pd.read_csv(f'../data/{model}/{model}_agent_{agent}_sim_{sim}.csv')))\n",
    "        all_data.append(data_per_block)\n",
    "        \n",
    "    block_0 = all_data[0]\n",
    "    block_1 = all_data[1]\n",
    "    block_2 = all_data[2]\n",
    "\n",
    "    all_blocks = [block_0,block_1,block_2]\n",
    "\n",
    "    return all_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "896d3a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weight_changes_between_states(network_state_t, network_state_t_plus_1):\n",
    "    \"\"\"\n",
    "    Calculate weight changes between two consecutive network states.\n",
    "    \n",
    "    Args:\n",
    "        network_state_t: Network state at time t\n",
    "        network_state_t_plus_1: Network state at time t+1\n",
    "        \n",
    "    Returns:\n",
    "        numpy.ndarray: Matrix where each row represents flattened weight changes\n",
    "    \"\"\"\n",
    "    weight_changes_list = []\n",
    "    \n",
    "    # Iterate through corresponding parameters in both network states\n",
    "    params_t = dict(network_state_t.named_parameters())\n",
    "    params_t_plus_1 = dict(network_state_t_plus_1.named_parameters())\n",
    "\n",
    "    for name in params_t.keys():     \n",
    "        # Only consider weight matrices, not biases\n",
    "        if 'weight' in name:\n",
    "            # Calculate weight difference and convert to numpy\n",
    "            weight_difference = params_t_plus_1[name].data - params_t[name].data\n",
    "            # Flatten the weight difference matrix into a vector\n",
    "            weight_changes_list.append(weight_difference.flatten().cpu().numpy())\n",
    "            \n",
    "    # Stack vectors vertically to create weight changes matrix\n",
    "    return np.concatenate(weight_changes_list)  \n",
    "\n",
    "def calculate_weight_changes_rank(net, network_states_per_epoch, test_loss, window_size=5):\n",
    "    \"\"\"\n",
    "    Calculate the rank of weight changes matrix around the optimal epoch.\n",
    "    \n",
    "    Args:\n",
    "        net: The trained neural network\n",
    "        network_states_per_epoch: List of network states from training\n",
    "        val_loss: Validation loss array from training\n",
    "        window_size: Number of epochs to consider before and after optimal epoch\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (weight_changes_rank, optimal_epoch_idx)\n",
    "    \"\"\"\n",
    "    # Find optimal epoch based on validation loss\n",
    "    optimal_epoch_idx = np.argmin(test_loss)\n",
    "    \n",
    "    # Calculate weight changes around optimal epoch\n",
    "    weight_changes_matrix_list = []\n",
    "    \n",
    "    # Consider window_size epochs before and after the optimal epoch\n",
    "    start_epoch = max(0, optimal_epoch_idx - window_size)\n",
    "    end_epoch = min(len(network_states_per_epoch) - 1, optimal_epoch_idx + window_size)\n",
    "    \n",
    "    for t in range(start_epoch, end_epoch):\n",
    "        # Create temporary networks for states at t and t+1\n",
    "        network_at_t = GRU_NN(INPUT_SIZE, net.hidden_size, 1, OUTPUT_SIZE).to(device)\n",
    "        network_at_t_plus_1 = GRU_NN(INPUT_SIZE, net.hidden_size, 1, OUTPUT_SIZE).to(device)\n",
    "        \n",
    "        # Load states\n",
    "        network_at_t.load_state_dict(network_states_per_epoch[t])\n",
    "        network_at_t_plus_1.load_state_dict(network_states_per_epoch[t + 1])\n",
    "        \n",
    "        # Compute weight changes between consecutive states\n",
    "        weight_changes = compute_weight_changes_between_states(\n",
    "            network_at_t, network_at_t_plus_1)\n",
    "        weight_changes_matrix_list.append(weight_changes)\n",
    "    \n",
    "    # Combine all weight changes into single matrix\n",
    "    complete_weight_changes_matrix = np.hstack(weight_changes_matrix_list)\n",
    "    \n",
    "    # Calculate rank of weight changes matrix\n",
    "    weight_changes_rank = np.linalg.matrix_rank(complete_weight_changes_matrix)\n",
    "    \n",
    "    return weight_changes_rank, optimal_epoch_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e649eca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = num_of_agents\n",
    "\n",
    "INPUT_SIZE = 4 # 3 for the action (one-hot format) and 1 for the reward of the chosen action\n",
    "OUTPUT_SIZE = 3 # probabilities of choosing each action in the next trial\n",
    "LERANING_RATE = 0.001\n",
    "\n",
    "hidden_size = 5\n",
    "num_layers = 1\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "611ed754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rnn_for_model(all_blocks, model):\n",
    "    loss_train, loss_val, loss_test  = [], [], []\n",
    "    ll_train, ll_val, ll_test = [], [], []\n",
    "    ranks, optimal_epochs = [], []\n",
    "\n",
    "    for n in tqdm(range(N)):\n",
    "        network_states_per_epoch = []\n",
    "        for train, val, test in cv:\n",
    "\n",
    "            train_data = behavior_dataset(all_blocks[train][n])\n",
    "            val_data = behavior_dataset(all_blocks[val][n])\n",
    "            test_data = behavior_dataset(all_blocks[test][n])\n",
    "\n",
    "            train_loader = DataLoader(train_data,shuffle=False,batch_size=len(train_data))\n",
    "            val_loader = DataLoader(val_data,shuffle=False,batch_size=len(val_data))\n",
    "            test_loader = DataLoader(test_data,shuffle=False,batch_size=len(test_data))\n",
    "            \n",
    "            rnn = GRU_NN(INPUT_SIZE, hidden_size, num_layers, OUTPUT_SIZE)\n",
    "            rnn, train_loss, train_ll, val_loss, val_ll, test_loss, test_ll, network_states_per_epoch = train_model(rnn,\n",
    "                                                                                    train_loader,\n",
    "                                                                                    val_loader,\n",
    "                                                                                    test_loader,\n",
    "                                                                                    epochs=epochs,\n",
    "                                                                                    lr=LERANING_RATE) \n",
    "            \n",
    "            rank, optimal_epoch = calculate_weight_changes_rank(rnn, network_states_per_epoch, test_loss)\n",
    "                                                                                                                                        \n",
    "            loss_train.append(train_loss)\n",
    "            loss_val.append(val_loss)\n",
    "            loss_test.append(test_loss)\n",
    "            \n",
    "            ll_train.append(train_ll)\n",
    "            ll_val.append(val_ll)\n",
    "            ll_test.append(test_ll)\n",
    "\n",
    "            ranks.append(rank)\n",
    "            optimal_epochs.append(optimal_epoch)\n",
    "            \n",
    "        print('Done agent',n)\n",
    "        \n",
    "        \n",
    "    with open(f'../results/{model}_loss_train.pickle', 'wb') as handle:\n",
    "        pickle.dump(loss_train, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    with open(f'../results/{model}_loss_val.pickle', 'wb') as handle:\n",
    "        pickle.dump(loss_val, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    with open(f'../results/{model}_loss_test.pickle', 'wb') as handle:\n",
    "        pickle.dump(loss_test, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    with open(f'../results/{model}_ll_train.pickle', 'wb') as handle:\n",
    "        pickle.dump(ll_train, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    with open(f'../results/{model}_ll_val.pickle', 'wb') as handle:\n",
    "        pickle.dump(ll_val, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    with open(f'../results/{model}_ll_test.pickle', 'wb') as handle:\n",
    "        pickle.dump(ll_test, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    with open(f'../results/{model}_ranks.pickle', 'wb') as handle:\n",
    "        pickle.dump(ranks, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    with open(f'../results/{model}_optimal_epochs.pickle', 'wb') as handle:\n",
    "        pickle.dump(optimal_epochs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    return loss_train, loss_val, loss_test, ll_train, ll_val, ll_test, ranks, optimal_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bef986c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(model):\n",
    "    # Load the results from pickle files\n",
    "    file_paths = {\n",
    "        \"loss_train\": f\"../results/{model}_loss_train.pickle\",\n",
    "        \"loss_val\": f\"../results/{model}_loss_val.pickle\",\n",
    "        \"loss_test\": f\"../results/{model}_loss_test.pickle\",\n",
    "        \"ll_train\": f\"../results/{model}_ll_train.pickle\",\n",
    "        \"ll_val\": f\"../results/{model}_ll_val.pickle\",\n",
    "        \"ll_test\": f\"../results/{model}_ll_test.pickle\",\n",
    "        # \"ranks\": f\"../results/{model}_ranks.pickle\",\n",
    "        # \"optimal_epochs\": f\"../results/{model}_optimal_epochs.pickle\"\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "    for key, path in file_paths.items():\n",
    "        with open(path, 'rb') as handle:\n",
    "            results[key] = pickle.load(handle)\n",
    "\n",
    "    # Convert lists of lists to averaged lists per epoch\n",
    "    epochs = len(results[\"loss_train\"][0])  # Assuming all have the same epoch length\n",
    "    avg_results = {key: [sum(epoch) / len(epoch) for epoch in zip(*values)] for key, values in results.items()}\n",
    "\n",
    "    # Plotting loss and log-likelihood\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    # Loss plot\n",
    "    axes[0].plot(range(epochs), avg_results[\"loss_train\"], label=\"Train Loss\", marker=\"o\")\n",
    "    axes[0].plot(range(epochs), avg_results[\"loss_val\"], label=\"Validation Loss\", marker=\"s\")\n",
    "    axes[0].plot(range(epochs), avg_results[\"loss_test\"], label=\"Test Loss\", marker=\"^\")\n",
    "    axes[0].set_title(\"Loss Over Epochs\")\n",
    "    axes[0].set_xlabel(\"Epochs\")\n",
    "    axes[0].set_ylabel(\"Loss\")\n",
    "    axes[0].legend()\n",
    "\n",
    "    # Log-likelihood plot\n",
    "    axes[1].plot(range(epochs), avg_results[\"ll_train\"], label=\"Train Log-Likelihood\", marker=\"o\")\n",
    "    axes[1].plot(range(epochs), avg_results[\"ll_val\"], label=\"Validation Log-Likelihood\", marker=\"s\")\n",
    "    axes[1].plot(range(epochs), avg_results[\"ll_test\"], label=\"Test Log-Likelihood\", marker=\"^\")\n",
    "    axes[1].set_title(\"Log-Likelihood Over Epochs\")\n",
    "    axes[1].set_xlabel(\"Epochs\")\n",
    "    axes[1].set_ylabel(\"Log-Likelihood\")\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb03d0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 1/40 [03:29<2:16:05, 209.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2/40 [06:58<2:12:38, 209.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 3/40 [10:31<2:10:10, 211.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 4/40 [13:58<2:05:31, 209.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 5/40 [17:22<2:00:57, 207.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 6/40 [20:41<1:55:52, 204.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 7/40 [24:04<1:52:17, 204.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 8/40 [27:21<1:47:36, 201.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 9/40 [30:37<1:43:16, 199.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 10/40 [33:54<1:39:36, 199.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 11/40 [37:18<1:36:59, 200.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 12/40 [40:37<1:33:19, 199.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 13/40 [43:56<1:29:50, 199.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 14/40 [47:14<1:26:18, 199.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 15/40 [50:32<1:22:56, 199.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 16/40 [53:50<1:19:28, 198.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▎     | 17/40 [57:08<1:16:01, 198.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 18/40 [1:00:26<1:12:44, 198.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 19/40 [1:03:44<1:09:25, 198.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 20/40 [1:07:02<1:06:02, 198.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 21/40 [1:10:27<1:03:22, 200.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 22/40 [1:13:45<59:52, 199.60s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▊    | 23/40 [1:17:03<56:21, 198.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 24/40 [1:20:19<52:50, 198.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 25/40 [1:23:31<49:05, 196.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 26/40 [1:26:46<45:40, 195.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 27/40 [1:30:09<42:56, 198.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 28/40 [1:33:32<39:55, 199.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▎  | 29/40 [1:36:55<36:46, 200.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 30/40 [1:40:18<33:32, 201.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 31/40 [1:43:41<30:16, 201.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 32/40 [1:47:04<26:57, 202.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▎ | 33/40 [1:50:27<23:36, 202.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 34/40 [1:53:42<20:00, 200.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 35/40 [1:56:55<16:30, 198.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 36/40 [2:00:09<13:07, 196.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▎| 37/40 [2:03:23<09:48, 196.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 38/40 [2:06:37<06:30, 195.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 39/40 [2:09:51<03:15, 195.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [2:13:05<00:00, 199.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▎         | 1/40 [03:13<2:05:43, 193.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2/40 [06:26<2:02:27, 193.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 3/40 [09:40<1:59:25, 193.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 4/40 [12:54<1:56:10, 193.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 5/40 [16:07<1:52:54, 193.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 6/40 [19:21<1:49:47, 193.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 7/40 [22:35<1:46:33, 193.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 8/40 [25:49<1:43:24, 193.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 9/40 [29:03<1:40:10, 193.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 10/40 [32:17<1:36:57, 193.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 11/40 [35:31<1:33:39, 193.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 12/40 [38:44<1:30:18, 193.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 13/40 [41:57<1:27:05, 193.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 14/40 [45:11<1:23:53, 193.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 15/40 [48:24<1:20:36, 193.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 16/40 [51:44<1:18:10, 195.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done agent 15\n"
     ]
    }
   ],
   "source": [
    "models = [\"none\", \"exploration_only\", \"noise_only\", \"both\"]\n",
    "optimal_epochs_per_model = {}\n",
    "ranks_per_model = {}\n",
    "test_losses_per_model = {}\n",
    "\n",
    "for model in models:\n",
    "    all_blocks = upload_data(num_of_block,num_of_agents,model)\n",
    "    loss_train, loss_val, loss_test, ll_train, ll_val, ll_test, ranks, optimal_epochs = train_rnn_for_model(all_blocks, model)\n",
    "    #plot_results(model)\n",
    "    optimal_epochs_per_model[model] = optimal_epochs\n",
    "    ranks_per_model[model] = ranks\n",
    "    test_losses_per_model[model] = loss_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8478697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The bug was in plot resutls, I fixed it but I moved it to a new loop and code block so that all of the data will be saved before we procceed\n",
    "for model in models:\n",
    "    plot_results(model)\n",
    "\n",
    "#plot optimal epochs by model\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "for model, optimal_epochs in optimal_epochs_per_model.items():\n",
    "    sns.histplot(optimal_epochs, kde=True, label=model, ax=ax)\n",
    "ax.set_title(\"Optimal Epochs\")\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#plot ranks by model\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "for model, ranks in ranks_per_model.items():\n",
    "    sns.histplot(ranks, kde=True, label=model, ax=ax)\n",
    "ax.set_title(\"Rank of Weight Changes Matrix Around Optimal Epoch\")\n",
    "ax.set_xlabel(\"Rank\")\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "#plot test losses by epoch, grouped by model\n",
    "# fig, ax = plt.subplots(figsize=(10, 5))\n",
    "# for model, test_losses in test_losses_per_model.items():\n",
    "#     for test_loss in test_losses:\n",
    "#         ax.plot(range(len(test_loss)), test_loss, label=model)\n",
    "# ax.set_title(\"Test Loss Over Epochs\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
