{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "805c8b47",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plot_stats'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sg/xn89shp907j6tn601y5lns7w0000gn/T/ipykernel_22467/3655012775.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimports\u001b[0m \u001b[0;32mimport\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlogistic_regression\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/rnn_iq/simulation/code/helper/logistic_regression.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mplot_stats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plot_stats'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import multiprocessing as mp\n",
    "import pickle \n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from imports import*\n",
    "from utils import *\n",
    "from logistic_regression import *\n",
    "from rnn import *\n",
    "\n",
    "from hybrid_sim import *\n",
    "from hybrid_fit import *\n",
    "from hybrid_predict import *\n",
    "\n",
    "from habit_sim import *\n",
    "from habit_fit import *\n",
    "from habit_predict import *\n",
    "\n",
    "from kdh_sim import *\n",
    "from kdh_fit import *\n",
    "from kdh_predict import *\n",
    "\n",
    "\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4a4df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num of agent\n",
    "num_of_agents = 5\n",
    "\n",
    "# num of block\n",
    "num_of_block = 3\n",
    "\n",
    "# num of trials \n",
    "num_of_trials = 200\n",
    "\n",
    "# for cross valdation \n",
    "array = np.arange(num_of_block)\n",
    "cv = [np.roll(array,i) for i in range(num_of_block)]\n",
    "cv = np.array(cv)\n",
    "\n",
    "models = {\n",
    "\n",
    "    'hybrid':[ configuration_parameters_hybrid,\n",
    "               hybrid_sim,\n",
    "               hybrid_fit,\n",
    "               hybrid_predict],\n",
    "    \n",
    "    'habit':[  configuration_parameters_habit,\n",
    "               habit_sim,\n",
    "               habit_fit,\n",
    "               habit_predict],\n",
    "    \n",
    "    'kdh':  [  configuration_parameters_kdh,\n",
    "               kdh_sim,\n",
    "               kdh_fit,\n",
    "               kdh_predict]\n",
    "}\n",
    "\n",
    "\n",
    "def bce(y_hat,y_true):\n",
    "    eps = 1e-7\n",
    "    return -np.sum( y_true*np.log(y_hat+eps) + (1-y_true)*np.log(1-y_hat+eps) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8447e015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim\n",
    "for m in models:\n",
    "    print(f'Model {m}')\n",
    "    \n",
    "    data_per_agent = []\n",
    "    parameters = []\n",
    "\n",
    "    for agent in tqdm(range(num_of_agents)):\n",
    "        param = models[m][0]()\n",
    "        parameters.append(param)\n",
    "        \n",
    "        data = []\n",
    "        for i in range(num_of_block):\n",
    "            # create rewards probs \n",
    "            reward_probs = create_rndwlk(4,num_of_trials)\n",
    "            df = models[m][1](\n",
    "                            param,\n",
    "                            num_of_trials,\n",
    "                            reward_probs\n",
    "            ) \n",
    "            data.append(df)\n",
    "        data_per_agent.append(data)\n",
    "\n",
    "    df = pd.DataFrame(parameters)\n",
    "    df.to_csv(f'../results/{m}/{m}_parameters.csv')\n",
    "    \n",
    "    for agent in range(num_of_agents):\n",
    "        for block in range(num_of_block):\n",
    "            data_per_agent[agent][block].to_csv(f'../data/{m}/{m}_agent_{agent}_sim_{block}.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af18874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload data\n",
    "all_data = [] \n",
    "for sim in range(num_of_block):\n",
    "    data_per_block = []\n",
    "    for m in tqdm(models): \n",
    "        for agent in range(num_of_agents):\n",
    "            data_per_block.append((pd.read_csv(f'../data/{m}/{m}_agent_{agent}_sim_{sim}.csv')))\n",
    "    all_data.append(data_per_block)\n",
    "    \n",
    "block_0 = all_data[0]\n",
    "block_1 = all_data[1]\n",
    "block_2 = all_data[2]\n",
    "\n",
    "all_blocks = [block_0,block_1,block_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b6e56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_results = {\n",
    "    \n",
    "   'agent': [],\n",
    "   'model': [],\n",
    "   'train_block': [],\n",
    "    \n",
    "   'train_nll_hybrid' : [],\n",
    "   'val_nll_hybrid' : [],\n",
    "   'test_nll_hybrid': [], \n",
    "\n",
    "   'train_nll_habit' : [], \n",
    "   'val_nll_habit' : [],\n",
    "   'test_nll_habit': [], \n",
    "\n",
    "   'train_nll_kdh' : [], \n",
    "   'val_nll_kdh' : [],\n",
    "   'test_nll_kdh': [], \n",
    "    \n",
    "}\n",
    "\n",
    "K = 5\n",
    "N = num_of_agents*num_of_block\n",
    "data_results['agent'].append(np.tile(np.arange(0,N),len(cv)))\n",
    "data_results['train_block'].append(np.repeat(cv[:,0],N))\n",
    "data_results['model'].append(np.tile(np.repeat(['hybrid','habit','kdh'],num_of_agents),num_of_block))\n",
    "\n",
    "\n",
    "for m in tqdm(models): \n",
    "\n",
    "    print(f'*** Fit with {m} ***')\n",
    "    \n",
    "    for train, val, test in cv:\n",
    "        print(f'*** train {train} | val {val} | test {test} ***')\n",
    "        \n",
    "        # fit k times \n",
    "        fit_res = []\n",
    "        for _ in range(K):\n",
    "            pool = mp.Pool(processes=mp.cpu_count())\n",
    "            fit = pool.map(models[m][2], all_blocks[train])\n",
    "            pool.close()\n",
    "            fit_res.append(fit)\n",
    "            \n",
    "        # best train/validation nll    \n",
    "        all_nll_train = np.zeros(shape=(K,N))\n",
    "        all_nll_val = np.zeros(shape=(K,N))\n",
    "        all_nll_test = np.zeros(shape=(K,N))\n",
    "        best_parameters = [] \n",
    "        for k in range(K):\n",
    "            for n in range(N):\n",
    "                _ , y_hat, _ = models[m][3](all_blocks[train][n], fit_res[k][n].x)\n",
    "                nLL = bce(1-y_hat, all_blocks[train][n]['action_stage_1'].values)\n",
    "                all_nll_train[k,n] =  nLL\n",
    "                \n",
    "                _ , y_hat, _ = models[m][3](all_blocks[val][n], fit_res[k][n].x)\n",
    "                nLL = bce(1-y_hat, all_blocks[val][n]['action_stage_1'].values)\n",
    "                all_nll_val[k,n] = nLL\n",
    "                \n",
    "                _ , y_hat, _ = models[m][3](all_blocks[test][n], fit_res[k][n].x)\n",
    "                nLL = bce(1-y_hat, all_blocks[test][n]['action_stage_1'].values)\n",
    "                all_nll_test[k,n] = nLL\n",
    "                \n",
    "        best_train = all_nll_train.min(axis=0)\n",
    "        best_val = all_nll_val.min(axis=0)\n",
    "        indx = np.argmin(all_nll_val,axis=0)\n",
    "        best_test = np.array([all_nll_test[indx[n],n] for n in range(N)])\n",
    "\n",
    "        data_results[f'train_nll_{m}'].append(best_train)\n",
    "        data_results[f'val_nll_{m}'].append(best_val)\n",
    "        data_results[f'test_nll_{m}'].append(best_test)\n",
    "        \n",
    "\n",
    "for k in data_results:\n",
    "    data_results[k] = np.concatenate(data_results[k])\n",
    "df_the = pd.DataFrame(data_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb2d70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "N = num_of_agents*num_of_block\n",
    "\n",
    "data_results_lr = {\n",
    "        \n",
    "   'train_nll_lr' : [],\n",
    "   'val_nll_lr' : [],\n",
    "   'test_nll_lr': [], \n",
    "    \n",
    "}\n",
    "\n",
    "for train, val, test in cv:\n",
    "    print(f'*** train {train} | val {val} | test {test} ***')\n",
    "    \n",
    "    all_nll_train = np.zeros(shape=(K,N))\n",
    "    all_nll_val = np.zeros(shape=(K,N))\n",
    "    all_nll_test = np.zeros(shape=(K,N))\n",
    "    \n",
    "    fit_res = []    \n",
    "    for k in range(K):\n",
    "        cur_res = []\n",
    "        for n in range(N):\n",
    "            X, y = preprocess_logistic_regression(all_blocks[train][n],lag=k+1)\n",
    "            clf, inter, coef = fit_logistic_regression(X,y)\n",
    "            cur_res.append(clf)\n",
    "        fit_res.append(cur_res)\n",
    "            \n",
    "    # best train/validation nll    \n",
    "    for k in range(K):\n",
    "        for n in range(N):\n",
    "            clf = fit_res[k][n]\n",
    "            \n",
    "            # train\n",
    "            X, y = preprocess_logistic_regression(all_blocks[train][n],lag=k+1)\n",
    "            if clf == None:\n",
    "                nLL = -np.log(.5)*200\n",
    "            else:\n",
    "                y_hat = clf.predict_proba(X)[:,0]\n",
    "                nLL = bce(1-y_hat, all_blocks[train][n]['action_stage_1'].values)\n",
    "            \n",
    "            all_nll_train[k,n] = nLL\n",
    "            \n",
    "            # validation\n",
    "            X, y = preprocess_logistic_regression(all_blocks[val][n],lag=k+1)\n",
    "            if clf == None:\n",
    "                nLL = -np.log(.5)*200\n",
    "            else:\n",
    "                y_hat = clf.predict_proba(X)[:,0]\n",
    "                nLL = bce(1-y_hat, all_blocks[val][n]['action_stage_1'].values)\n",
    "            \n",
    "            all_nll_val[k,n] = nLL\n",
    "\n",
    "            X, y = preprocess_logistic_regression(all_blocks[test][n],lag=k+1)            \n",
    "            if clf == None:\n",
    "                nLL = -np.log(.5)*200\n",
    "            else:\n",
    "                y_hat = clf.predict_proba(X)[:,0]\n",
    "                nLL = bce(1-y_hat, all_blocks[test][n]['action_stage_1'].values)\n",
    "                \n",
    "            all_nll_test[k,n] = nLL\n",
    "            \n",
    "    best_train = all_nll_train.min(axis=0)\n",
    "    best_val = all_nll_val.min(axis=0)\n",
    "    indx = np.argmin(all_nll_val,axis=0)\n",
    "    best_test = np.array([all_nll_test[indx[n],n] for n in range(N)])\n",
    "    \n",
    "    data_results_lr[f'train_nll_lr'].append(best_train)\n",
    "    data_results_lr[f'val_nll_lr'].append(best_val)\n",
    "    data_results_lr[f'test_nll_lr'].append(best_test)\n",
    "    \n",
    "for k in data_results_lr:\n",
    "    data_results_lr[k] = np.concatenate(data_results_lr[k])\n",
    "df_lr = pd.DataFrame(data_results_lr)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c980ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df_the,df_lr],axis=1).groupby('model').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957f35aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab18513",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "INPUT_SIZE = 5\n",
    "OUTPUT_SIZE = 2\n",
    "LERANING_RATE = 0.001\n",
    "\n",
    "hidden_size = 5\n",
    "num_layers = 1\n",
    "epochs = 1000\n",
    "\n",
    "loss_train, loss_val, loss_test  = [], [], []\n",
    "ll_train, ll_val, ll_test = [], [], []\n",
    "\n",
    "for n in tqdm(range(N)):\n",
    "    for train, val, test in cv:\n",
    "        print(f'*** train {train} | val {val} | test {test} ***')\n",
    "\n",
    "        train_data = behavior_dataset(all_blocks[train][n])\n",
    "        val_data = behavior_dataset(all_blocks[val][n])\n",
    "        test_data = behavior_dataset(all_blocks[test][n])\n",
    "\n",
    "        train_loader = DataLoader(train_data,shuffle=False,batch_size=len(train_data))\n",
    "        val_loader = DataLoader(val_data,shuffle=False,batch_size=len(val_data))\n",
    "        test_loader = DataLoader(test_data,shuffle=False,batch_size=len(test_data))\n",
    "        \n",
    "        rnn = GRU_NN(INPUT_SIZE, hidden_size, num_layers, OUTPUT_SIZE)\n",
    "        rnn, train_loss, train_ll, val_loss, val_ll, test_loss, test_ll = train_model(rnn, train_loader, val_loader, test_loader, epochs) \n",
    "                                                                                                                                       \n",
    "        loss_train.append(train_loss)\n",
    "        loss_val.append(val_loss)\n",
    "        loss_test.append(test_loss)\n",
    "        \n",
    "        ll_train.append(train_ll)\n",
    "        ll_val.append(val_ll)\n",
    "        ll_test.append(test_ll)\n",
    "        break\n",
    "        \n",
    "        \n",
    "    break\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2e4c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "plt.spines[\"top\"].set_visible(False)\n",
    "plt.spines[\"right\"].set_visible(False)\n",
    "plt.spines[\"left\"].set_visible(False)\n",
    "\n",
    "\n",
    "a,b,c,d = create_rndwlk(4,200)\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "plt.plot(a,color=sns.color_palette(\"tab10\" )[7],label='Reward P(1)',lw=2)\n",
    "plt.plot(b,color=sns.color_palette(\"tab10\" )[2],label='Reward P(2)',lw=2)\n",
    "plt.plot(c,color=sns.color_palette(\"tab10\" )[4],label='Reward P(3)',lw=2)\n",
    "plt.plot(d,color=sns.color_palette(\"tab10\" )[9],label='Reward P(4)',lw=2)\n",
    "plt.tick_params(which='major', labelsize=14)\n",
    "plt.grid(alpha=.1)\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "plt.xlabel('Trial',size=20)\n",
    "plt.ylabel('Probs',size=20)\n",
    "plt.savefig('fig_jax',dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
