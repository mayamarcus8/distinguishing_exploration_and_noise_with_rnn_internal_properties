{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "805c8b47",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'logistic_regression'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/sg/xn89shp907j6tn601y5lns7w0000gn/T/ipykernel_13272/2524074297.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mplot_stats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlogistic_regression\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'logistic_regression'"
     ]
    }
   ],
   "source": [
    "from imports import*\n",
    "\n",
    "from hybrid_sim import *\n",
    "from hybrid_fit import *\n",
    "from hybrid_predict import *\n",
    "\n",
    "from habit_sim import *\n",
    "from habit_fit import *\n",
    "from habit_predict import *\n",
    "\n",
    "from kdh_sim import *\n",
    "from kdh_fit import *\n",
    "from kdh_predict import *\n",
    "\n",
    "from utils import *\n",
    "from plot_stats import *\n",
    "from logistic_regression import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd4a4df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#config num of agent to simulate\n",
    "num_of_agents = 100\n",
    "\n",
    "#config num of trails for each block\n",
    "num_of_trials = 200\n",
    "\n",
    "#config num of block\n",
    "num_of_block = 5\n",
    "\n",
    "# for cross valdation \n",
    "array = np.arange(num_of_block)\n",
    "cv = [np.roll(array,i) for i in range(num_of_block)]\n",
    "cv = np.array(cv)\n",
    "\n",
    "models = {\n",
    "        'mf':[configuration_parameters_hybrid, mf_sim],\n",
    "        'mb':[configuration_parameters_hybrid, mb_sim],\n",
    "        'habit':[configuration_parameters_habit,habit_sim],\n",
    "        'wsls':[configuration_parameters_wsls,wsls_sim],\n",
    "        'kdh':[configuration_parameters_kdh,kdh_sim]\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c036369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model mf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:16<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model mb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:16<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model habit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:13<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model wsls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:09<00:00, 10.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model kdh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:09<00:00, 10.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# sim\n",
    "for m in models:\n",
    "    print(f'Model {m}')\n",
    "    \n",
    "    data_per_agent = []\n",
    "    parameters = []\n",
    "\n",
    "    for agent in tqdm(range(num_of_agents)):\n",
    "        param = models[m][0]()\n",
    "        parameters.append(param)\n",
    "        \n",
    "        data = []\n",
    "        for i in range(num_of_block):\n",
    "            # create rewards probs \n",
    "            reward_probs = create_rndwlk(4,num_of_trials)\n",
    "            df = models[m][1](\n",
    "                            param,\n",
    "                            num_of_trials,\n",
    "                            reward_probs\n",
    "            ) \n",
    "            data.append(df)\n",
    "        data_per_agent.append(data)\n",
    "\n",
    "    df = pd.DataFrame(parameters)\n",
    "    df.to_csv(f'../results/{m}/{m}_parameters.csv')\n",
    "    \n",
    "    for agent in range(num_of_agents):\n",
    "        for block in range(num_of_block):\n",
    "            data_per_agent[agent][block].to_csv(f'../data/{m}/{m}_agent_{agent}_sim_{block}.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c97e899b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Fit mf ***\n",
      "* agent 0 *\n",
      "* agent 1 *\n",
      "* agent 2 *\n",
      "* agent 3 *\n",
      "* agent 4 *\n",
      "* agent 5 *\n",
      "* agent 6 *\n",
      "* agent 7 *\n",
      "* agent 8 *\n",
      "* agent 9 *\n",
      "* agent 10 *\n",
      "* agent 11 *\n",
      "* agent 12 *\n",
      "* agent 13 *\n",
      "* agent 14 *\n",
      "* agent 15 *\n",
      "* agent 16 *\n",
      "* agent 17 *\n",
      "* agent 18 *\n",
      "* agent 19 *\n",
      "* agent 20 *\n",
      "* agent 21 *\n",
      "* agent 22 *\n",
      "* agent 23 *\n",
      "* agent 24 *\n",
      "* agent 25 *\n",
      "* agent 26 *\n",
      "* agent 27 *\n",
      "* agent 28 *\n",
      "* agent 29 *\n",
      "* agent 30 *\n",
      "* agent 31 *\n",
      "* agent 32 *\n",
      "* agent 33 *\n",
      "* agent 34 *\n",
      "* agent 35 *\n",
      "* agent 36 *\n",
      "* agent 37 *\n",
      "* agent 38 *\n",
      "* agent 39 *\n",
      "* agent 40 *\n",
      "* agent 41 *\n",
      "* agent 42 *\n",
      "* agent 43 *\n",
      "* agent 44 *\n",
      "* agent 45 *\n",
      "* agent 46 *\n",
      "* agent 47 *\n",
      "* agent 48 *\n",
      "* agent 49 *\n",
      "* agent 50 *\n",
      "* agent 51 *\n",
      "* agent 52 *\n",
      "* agent 53 *\n",
      "* agent 54 *\n",
      "* agent 55 *\n",
      "* agent 56 *\n",
      "* agent 57 *\n",
      "* agent 58 *\n",
      "* agent 59 *\n",
      "* agent 60 *\n",
      "* agent 61 *\n",
      "* agent 62 *\n",
      "* agent 63 *\n",
      "* agent 64 *\n",
      "* agent 65 *\n",
      "* agent 66 *\n",
      "* agent 67 *\n",
      "* agent 68 *\n",
      "* agent 69 *\n",
      "* agent 70 *\n",
      "* agent 71 *\n",
      "* agent 72 *\n",
      "* agent 73 *\n",
      "* agent 74 *\n",
      "* agent 75 *\n",
      "* agent 76 *\n",
      "* agent 77 *\n",
      "* agent 78 *\n",
      "* agent 79 *\n",
      "* agent 80 *\n",
      "* agent 81 *\n",
      "* agent 82 *\n",
      "* agent 83 *\n",
      "* agent 84 *\n",
      "* agent 85 *\n",
      "* agent 86 *\n",
      "* agent 87 *\n",
      "* agent 88 *\n",
      "* agent 89 *\n",
      "* agent 90 *\n",
      "* agent 91 *\n",
      "* agent 92 *\n",
      "* agent 93 *\n",
      "* agent 94 *\n",
      "* agent 95 *\n",
      "* agent 96 *\n",
      "* agent 97 *\n",
      "* agent 98 *\n",
      "* agent 99 *\n",
      "** save results mf **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████                                                                | 1/5 [23:09<1:32:36, 1389.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Fit mb ***\n",
      "* agent 0 *\n",
      "* agent 1 *\n",
      "* agent 2 *\n",
      "* agent 3 *\n",
      "* agent 4 *\n",
      "* agent 5 *\n",
      "* agent 6 *\n",
      "* agent 7 *\n",
      "* agent 8 *\n",
      "* agent 9 *\n",
      "* agent 10 *\n",
      "* agent 11 *\n",
      "* agent 12 *\n",
      "* agent 13 *\n",
      "* agent 14 *\n",
      "* agent 15 *\n",
      "* agent 16 *\n",
      "* agent 17 *\n",
      "* agent 18 *\n",
      "* agent 19 *\n",
      "* agent 20 *\n",
      "* agent 21 *\n",
      "* agent 22 *\n",
      "* agent 23 *\n",
      "* agent 24 *\n",
      "* agent 25 *\n",
      "* agent 26 *\n",
      "* agent 27 *\n",
      "* agent 28 *\n",
      "* agent 29 *\n",
      "* agent 30 *\n",
      "* agent 31 *\n",
      "* agent 32 *\n",
      "* agent 33 *\n",
      "* agent 34 *\n",
      "* agent 35 *\n",
      "* agent 36 *\n",
      "* agent 37 *\n",
      "* agent 38 *\n",
      "* agent 39 *\n",
      "* agent 40 *\n",
      "* agent 41 *\n",
      "* agent 42 *\n",
      "* agent 43 *\n",
      "* agent 44 *\n",
      "* agent 45 *\n",
      "* agent 46 *\n",
      "* agent 47 *\n",
      "* agent 48 *\n",
      "* agent 49 *\n",
      "* agent 50 *\n",
      "* agent 51 *\n",
      "* agent 52 *\n",
      "* agent 53 *\n",
      "* agent 54 *\n",
      "* agent 55 *\n",
      "* agent 56 *\n",
      "* agent 57 *\n",
      "* agent 58 *\n",
      "* agent 59 *\n",
      "* agent 60 *\n",
      "* agent 61 *\n",
      "* agent 62 *\n",
      "* agent 63 *\n",
      "* agent 64 *\n",
      "* agent 65 *\n",
      "* agent 66 *\n",
      "* agent 67 *\n",
      "* agent 68 *\n",
      "* agent 69 *\n",
      "* agent 70 *\n",
      "* agent 71 *\n",
      "* agent 72 *\n",
      "* agent 73 *\n",
      "* agent 74 *\n",
      "* agent 75 *\n",
      "* agent 76 *\n",
      "* agent 77 *\n",
      "* agent 78 *\n",
      "* agent 79 *\n",
      "* agent 80 *\n",
      "* agent 81 *\n",
      "* agent 82 *\n",
      "* agent 83 *\n",
      "* agent 84 *\n",
      "* agent 85 *\n",
      "* agent 86 *\n",
      "* agent 87 *\n",
      "* agent 88 *\n",
      "* agent 89 *\n",
      "* agent 90 *\n",
      "* agent 91 *\n",
      "* agent 92 *\n",
      "* agent 93 *\n",
      "* agent 94 *\n",
      "* agent 95 *\n",
      "* agent 96 *\n",
      "* agent 97 *\n",
      "* agent 98 *\n",
      "* agent 99 *\n",
      "** save results mb **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████                                                | 2/5 [45:17<1:07:39, 1353.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Fit habit ***\n",
      "* agent 0 *\n",
      "* agent 1 *\n",
      "* agent 2 *\n",
      "* agent 3 *\n",
      "* agent 4 *\n",
      "* agent 5 *\n",
      "* agent 6 *\n",
      "* agent 7 *\n",
      "* agent 8 *\n",
      "* agent 9 *\n",
      "* agent 10 *\n",
      "* agent 11 *\n",
      "* agent 12 *\n",
      "* agent 13 *\n",
      "* agent 14 *\n",
      "* agent 15 *\n",
      "* agent 16 *\n",
      "* agent 17 *\n",
      "* agent 18 *\n",
      "* agent 19 *\n",
      "* agent 20 *\n",
      "* agent 21 *\n",
      "* agent 22 *\n",
      "* agent 23 *\n",
      "* agent 24 *\n",
      "* agent 25 *\n",
      "* agent 26 *\n",
      "* agent 27 *\n",
      "* agent 28 *\n",
      "* agent 29 *\n",
      "* agent 30 *\n",
      "* agent 31 *\n",
      "* agent 32 *\n",
      "* agent 33 *\n",
      "* agent 34 *\n",
      "* agent 35 *\n",
      "* agent 36 *\n",
      "* agent 37 *\n",
      "* agent 38 *\n",
      "* agent 39 *\n",
      "* agent 40 *\n",
      "* agent 41 *\n",
      "* agent 42 *\n",
      "* agent 43 *\n",
      "* agent 44 *\n",
      "* agent 45 *\n",
      "* agent 46 *\n",
      "* agent 47 *\n",
      "* agent 48 *\n",
      "* agent 49 *\n",
      "* agent 50 *\n",
      "* agent 51 *\n",
      "* agent 52 *\n",
      "* agent 53 *\n",
      "* agent 54 *\n",
      "* agent 55 *\n",
      "* agent 56 *\n",
      "* agent 57 *\n",
      "* agent 58 *\n",
      "* agent 59 *\n",
      "* agent 60 *\n",
      "* agent 61 *\n",
      "* agent 62 *\n",
      "* agent 63 *\n",
      "* agent 64 *\n",
      "* agent 65 *\n",
      "* agent 66 *\n",
      "* agent 67 *\n",
      "* agent 68 *\n",
      "* agent 69 *\n",
      "* agent 70 *\n",
      "* agent 71 *\n",
      "* agent 72 *\n",
      "* agent 73 *\n",
      "* agent 74 *\n",
      "* agent 75 *\n",
      "* agent 76 *\n",
      "* agent 77 *\n",
      "* agent 78 *\n",
      "* agent 79 *\n",
      "* agent 80 *\n",
      "* agent 81 *\n",
      "* agent 82 *\n",
      "* agent 83 *\n",
      "* agent 84 *\n",
      "* agent 85 *\n",
      "* agent 86 *\n",
      "* agent 87 *\n",
      "* agent 88 *\n",
      "* agent 89 *\n",
      "* agent 90 *\n",
      "* agent 91 *\n",
      "* agent 92 *\n",
      "* agent 93 *\n",
      "* agent 94 *\n",
      "* agent 95 *\n",
      "* agent 96 *\n",
      "* agent 97 *\n",
      "* agent 98 *\n",
      "* agent 99 *\n",
      "** save results habit **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████████████████████████████                                | 3/5 [1:14:17<51:00, 1530.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Fit wsls ***\n",
      "* agent 0 *\n",
      "* agent 1 *\n",
      "* agent 2 *\n",
      "* agent 3 *\n",
      "* agent 4 *\n",
      "* agent 5 *\n",
      "* agent 6 *\n",
      "* agent 7 *\n",
      "* agent 8 *\n",
      "* agent 9 *\n",
      "* agent 10 *\n",
      "* agent 11 *\n",
      "* agent 12 *\n",
      "* agent 13 *\n",
      "* agent 14 *\n",
      "* agent 15 *\n",
      "* agent 16 *\n",
      "* agent 17 *\n",
      "* agent 18 *\n",
      "* agent 19 *\n",
      "* agent 20 *\n",
      "* agent 21 *\n",
      "* agent 22 *\n",
      "* agent 23 *\n",
      "* agent 24 *\n",
      "* agent 25 *\n",
      "* agent 26 *\n",
      "* agent 27 *\n",
      "* agent 28 *\n",
      "* agent 29 *\n",
      "* agent 30 *\n",
      "* agent 31 *\n",
      "* agent 32 *\n",
      "* agent 33 *\n",
      "* agent 34 *\n",
      "* agent 35 *\n",
      "* agent 36 *\n",
      "* agent 37 *\n",
      "* agent 38 *\n",
      "* agent 39 *\n",
      "* agent 40 *\n",
      "* agent 41 *\n",
      "* agent 42 *\n",
      "* agent 43 *\n",
      "* agent 44 *\n",
      "* agent 45 *\n",
      "* agent 46 *\n",
      "* agent 47 *\n",
      "* agent 48 *\n",
      "* agent 49 *\n",
      "* agent 50 *\n",
      "* agent 51 *\n",
      "* agent 52 *\n",
      "* agent 53 *\n",
      "* agent 54 *\n",
      "* agent 55 *\n",
      "* agent 56 *\n",
      "* agent 57 *\n",
      "* agent 58 *\n",
      "* agent 59 *\n",
      "* agent 60 *\n",
      "* agent 61 *\n",
      "* agent 62 *\n",
      "* agent 63 *\n",
      "* agent 64 *\n",
      "* agent 65 *\n",
      "* agent 66 *\n",
      "* agent 67 *\n",
      "* agent 68 *\n",
      "* agent 69 *\n",
      "* agent 70 *\n",
      "* agent 71 *\n",
      "* agent 72 *\n",
      "* agent 73 *\n",
      "* agent 74 *\n",
      "* agent 75 *\n",
      "* agent 76 *\n",
      "* agent 77 *\n",
      "* agent 78 *\n",
      "* agent 79 *\n",
      "* agent 80 *\n",
      "* agent 81 *\n",
      "* agent 82 *\n",
      "* agent 83 *\n",
      "* agent 84 *\n",
      "* agent 85 *\n",
      "* agent 86 *\n",
      "* agent 87 *\n",
      "* agent 88 *\n",
      "* agent 89 *\n",
      "* agent 90 *\n",
      "* agent 91 *\n",
      "* agent 92 *\n",
      "* agent 93 *\n",
      "* agent 94 *\n",
      "* agent 95 *\n",
      "* agent 96 *\n",
      "* agent 97 *\n",
      "* agent 98 *\n",
      "* agent 99 *\n",
      "** save results wsls **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████████████████████                | 4/5 [1:31:32<22:14, 1334.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Fit kdh ***\n",
      "* agent 0 *\n",
      "* agent 1 *\n",
      "* agent 2 *\n",
      "* agent 3 *\n",
      "* agent 4 *\n",
      "* agent 5 *\n",
      "* agent 6 *\n",
      "* agent 7 *\n",
      "* agent 8 *\n",
      "* agent 9 *\n",
      "* agent 10 *\n",
      "* agent 11 *\n",
      "* agent 12 *\n",
      "* agent 13 *\n",
      "* agent 14 *\n",
      "* agent 15 *\n",
      "* agent 16 *\n",
      "* agent 17 *\n",
      "* agent 18 *\n",
      "* agent 19 *\n",
      "* agent 20 *\n",
      "* agent 21 *\n",
      "* agent 22 *\n",
      "* agent 23 *\n",
      "* agent 24 *\n",
      "* agent 25 *\n",
      "* agent 26 *\n",
      "* agent 27 *\n",
      "* agent 28 *\n",
      "* agent 29 *\n",
      "* agent 30 *\n",
      "* agent 31 *\n",
      "* agent 32 *\n",
      "* agent 33 *\n",
      "* agent 34 *\n",
      "* agent 35 *\n",
      "* agent 36 *\n",
      "* agent 37 *\n",
      "* agent 38 *\n",
      "* agent 39 *\n",
      "* agent 40 *\n",
      "* agent 41 *\n",
      "* agent 42 *\n",
      "* agent 43 *\n",
      "* agent 44 *\n",
      "* agent 45 *\n",
      "* agent 46 *\n",
      "* agent 47 *\n",
      "* agent 48 *\n",
      "* agent 49 *\n",
      "* agent 50 *\n",
      "* agent 51 *\n",
      "* agent 52 *\n",
      "* agent 53 *\n",
      "* agent 54 *\n",
      "* agent 55 *\n",
      "* agent 56 *\n",
      "* agent 57 *\n",
      "* agent 58 *\n",
      "* agent 59 *\n",
      "* agent 60 *\n",
      "* agent 61 *\n",
      "* agent 62 *\n",
      "* agent 63 *\n",
      "* agent 64 *\n",
      "* agent 65 *\n",
      "* agent 66 *\n",
      "* agent 67 *\n",
      "* agent 68 *\n",
      "* agent 69 *\n",
      "* agent 70 *\n",
      "* agent 71 *\n",
      "* agent 72 *\n",
      "* agent 73 *\n",
      "* agent 74 *\n",
      "* agent 75 *\n",
      "* agent 76 *\n",
      "* agent 77 *\n",
      "* agent 78 *\n",
      "* agent 79 *\n",
      "* agent 80 *\n",
      "* agent 81 *\n",
      "* agent 82 *\n",
      "* agent 83 *\n",
      "* agent 84 *\n",
      "* agent 85 *\n",
      "* agent 86 *\n",
      "* agent 87 *\n",
      "* agent 88 *\n",
      "* agent 89 *\n",
      "* agent 90 *\n",
      "* agent 91 *\n",
      "* agent 92 *\n",
      "* agent 93 *\n",
      "* agent 94 *\n",
      "* agent 95 *\n",
      "* agent 96 *\n",
      "* agent 97 *\n",
      "* agent 98 *\n",
      "* agent 99 *\n",
      "** save results kdh **\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 5/5 [2:10:49<00:00, 1569.99s/it]\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "\n",
    "for m in tqdm(models):    \n",
    "    # load data \n",
    "    data_per_agent = []\n",
    "    for agent in range(num_of_agents):\n",
    "        data = []\n",
    "        for sim in range(num_of_block):\n",
    "            data.append(pd.read_csv(f'../data/{m}/{m}_agent_{agent}_sim_{sim}.csv'))\n",
    "        data_per_agent.append(data)\n",
    "        \n",
    "    data_results = {\n",
    "                   'agent': [], \n",
    "                   'fit_parameters_mf': [], \n",
    "                   'train_nlp_mf' : [], \n",
    "                   'test_acc_mf': [],\n",
    "                   'test_nlp_mf': [], \n",
    "\n",
    "                   'fit_parameters_mb': [], \n",
    "                   'train_nlp_mb' : [], \n",
    "                   'test_acc_mb': [],\n",
    "                   'test_nlp_mb': [],\n",
    "        \n",
    "                   'fit_parameters_habit': [], \n",
    "                   'train_nlp_habit' : [], \n",
    "                   'test_acc_habit': [],\n",
    "                   'test_nlp_habit': [], \n",
    "        \n",
    "                    'fit_parameters_wsls': [], \n",
    "                   'train_nlp_wsls' : [], \n",
    "                   'test_acc_wsls': [],\n",
    "                   'test_nlp_wsls': [], \n",
    "\n",
    "                   'fit_parameters_kdh': [], \n",
    "                   'train_nlp_kdh' : [], \n",
    "                   'test_acc_kdh': [],\n",
    "                   'test_nlp_kdh': [], \n",
    "\n",
    "                   'fit_parameters_logistic_regression': [], \n",
    "                   'train_nlp_logistic_regression' : [], \n",
    "                   'test_acc_logistic_regression': [],\n",
    "                   'test_nlp_logistic_regression': [],\n",
    "\n",
    "            }\n",
    "    print(f'*** Fit {m} ***')\n",
    "    for agent in range(num_of_agents):\n",
    "        print(f'* agent {agent} *')\n",
    "        for n,t in enumerate(cv):\n",
    "            data_results['agent'].append(agent)\n",
    "            train_arr = t[0:-1]\n",
    "            test_arr = t[-1:]\n",
    "\n",
    "            # split train and test data\n",
    "            train_data = [data_per_agent[agent][sim] for sim in train_arr]\n",
    "            train_data = pd.concat(train_data) \n",
    "            train_data.reset_index(inplace=True)\n",
    "            n_train = len(train_data)\n",
    "\n",
    "            test_data = [data_per_agent[agent][sim] for sim in test_arr]\n",
    "            test_data = pd.concat(test_data) \n",
    "            test_data.reset_index(inplace=True)\n",
    "            n_test = len(test_data)\n",
    "            \n",
    "            # fit mf \n",
    "            res = mf_fit(train_data,2)\n",
    "            data_results['fit_parameters_mf'].append(res.x)\n",
    "\n",
    "            # Train log probability\n",
    "            data_results['train_nlp_mf'].append(res.fun/n_train)\n",
    "\n",
    "            # Test Accuracy and loss\n",
    "            accuracy, p_0, _ = mf_predict(test_data,res.x)\n",
    "\n",
    "            # Test Accuracy\n",
    "            data_results['test_acc_mf'].append(accuracy/n_test)\n",
    "\n",
    "            # Test negative log probability\n",
    "            running_loss = 0\n",
    "            for row in test_data.itertuples(index=True, name='Pandas'):\n",
    "                y_pred = torch.tensor([1-p_0[row.Index]],dtype=torch.float32)\n",
    "                y_true = torch.tensor([row.action_stage_1],dtype=torch.float32)\n",
    "                running_loss += (criterion(y_pred,y_true)).numpy()\n",
    "            data_results['test_nlp_mf'].append((running_loss/n_test))\n",
    "            \n",
    "            # fit mb\n",
    "            res = mb_fit(train_data,2)\n",
    "            data_results['fit_parameters_mb'].append(res.x)\n",
    "\n",
    "            # Train negative log probability\n",
    "            data_results['train_nlp_mb'].append(res.fun/n_train)\n",
    "\n",
    "            # Test Accuracy and loss\n",
    "            accuracy, p_0, _ = mb_predict(test_data,res.x)\n",
    "\n",
    "            # Test Accuracy\n",
    "            data_results['test_acc_mb'].append(accuracy/n_test)\n",
    "\n",
    "            # Test negative log probability\n",
    "            running_loss = 0\n",
    "            for row in test_data.itertuples(index=True, name='Pandas'):\n",
    "                y_pred = torch.tensor([1-p_0[row.Index]],dtype=torch.float32)\n",
    "                y_true = torch.tensor([row.action_stage_1],dtype=torch.float32)\n",
    "                running_loss += (criterion(y_pred,y_true)).numpy()\n",
    "            data_results['test_nlp_mb'].append((running_loss/n_test))\n",
    "            \n",
    "            # fit habit\n",
    "            res = habit_fit(train_data,2)\n",
    "            data_results['fit_parameters_habit'].append(res.x)\n",
    "\n",
    "            # Train negative log probability\n",
    "            data_results['train_nlp_habit'].append(res.fun/n_train)\n",
    "\n",
    "            # Test Accuracy and loss\n",
    "            accuracy, p_0, _ = habit_predict(test_data,res.x)\n",
    "\n",
    "            # Test Accuracy\n",
    "            data_results['test_acc_habit'].append(accuracy/n_test)\n",
    "\n",
    "            # Test negative log probability\n",
    "            running_loss = 0\n",
    "            for row in test_data.itertuples(index=True, name='Pandas'):\n",
    "                y_pred = torch.tensor([1-p_0[row.Index]],dtype=torch.float32)\n",
    "                y_true = torch.tensor([row.action_stage_1],dtype=torch.float32)\n",
    "                running_loss += (criterion(y_pred,y_true)).numpy()\n",
    "            data_results['test_nlp_habit'].append((running_loss/n_test))\n",
    "            \n",
    "            # fit wsls\n",
    "            res = wsls_fit(train_data,2)\n",
    "            data_results['fit_parameters_wsls'].append(res.x)\n",
    "\n",
    "            # Train negative log probability\n",
    "            data_results['train_nlp_wsls'].append(res.fun/n_train)\n",
    "\n",
    "            # Test Accuracy and loss\n",
    "            accuracy, p_0, _ = wsls_predict(test_data,res.x)\n",
    "\n",
    "            # Test Accuracy\n",
    "            data_results['test_acc_wsls'].append(accuracy/n_test)\n",
    "\n",
    "            # Test negative log probability\n",
    "            running_loss = 0\n",
    "            for row in test_data.itertuples(index=True, name='Pandas'):\n",
    "                y_pred = torch.tensor([1-p_0[row.Index]],dtype=torch.float32)\n",
    "                y_true = torch.tensor([row.action_stage_1],dtype=torch.float32)\n",
    "                running_loss += (criterion(y_pred,y_true)).numpy()\n",
    "            data_results['test_nlp_wsls'].append((running_loss/n_test))\n",
    "            \n",
    "            # fit kDH\n",
    "            res = kdh_fit(train_data,2)\n",
    "            data_results['fit_parameters_kdh'].append(res.x)\n",
    "\n",
    "            # Train negative log probability\n",
    "            data_results['train_nlp_kdh'].append(res.fun/n_train)\n",
    "\n",
    "            # Test Accuracy and loss\n",
    "            accuracy, p_0, _ = kdh_predict(test_data,res.x)\n",
    "\n",
    "            # Test Accuracy\n",
    "            data_results['test_acc_kdh'].append(accuracy/n_test)\n",
    "\n",
    "            # Test negative log probability\n",
    "            running_loss = 0\n",
    "            for row in test_data.itertuples(index=True, name='Pandas'):\n",
    "                y_pred = torch.tensor([1-p_0[row.Index]],dtype=torch.float32)\n",
    "                y_true = torch.tensor([row.action_stage_1],dtype=torch.float32)\n",
    "                running_loss += (criterion(y_pred,y_true)).numpy()\n",
    "            data_results['test_nlp_kdh'].append((running_loss/n_test))\n",
    "\n",
    "            X , y = preprocess_logistic_regression(train_data)\n",
    "            model, intercept, coef  = fit_logistic_regression(X,y)\n",
    "            data_results['fit_parameters_logistic_regression'].append([intercept,coef])\n",
    "            \n",
    "            if m == None:\n",
    "                print('hi')\n",
    "                data_results['train_nlp_logistic_regression'].append(-1)\n",
    "                data_results['test_acc_logistic_regression'].append(-1)\n",
    "                data_results['test_nlp_logistic_regression'].append(-1)\n",
    "    \n",
    "            else:\n",
    "                # Train negative log probability\n",
    "                nlp = nlp_logistic_regression(model,X,y)\n",
    "                data_results['train_nlp_logistic_regression'].append((nlp/n_train))\n",
    "\n",
    "                # test data \n",
    "                X, y = preprocess_logistic_regression(test_data)\n",
    "                # Test Accuracy\n",
    "                accuracy = model.score(X,y)\n",
    "                data_results['test_acc_logistic_regression'].append(accuracy)\n",
    "\n",
    "                # Test negative log probability\n",
    "                nlp = nlp_logistic_regression(model,X,y)\n",
    "                data_results['test_nlp_logistic_regression'].append((nlp/n_test))\n",
    "               \n",
    "    print(f'** save results {m} **')\n",
    "    # save data \n",
    "    df = pd.DataFrame(data_results)\n",
    "    df.to_csv(f'../results/{m}/{m}_fit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "270b3458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e88c4_row0_col0, #T_e88c4_row1_col1, #T_e88c4_row2_col2, #T_e88c4_row3_col3, #T_e88c4_row4_col4 {\n",
       "  background-color: #440154;\n",
       "  color: #f1f1f1;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_e88c4_row0_col1, #T_e88c4_row1_col4, #T_e88c4_row4_col0, #T_e88c4_row4_col2, #T_e88c4_row4_col3 {\n",
       "  background-color: #fde725;\n",
       "  color: #000000;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_e88c4_row0_col2, #T_e88c4_row0_col3 {\n",
       "  background-color: #8bd646;\n",
       "  color: #000000;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_e88c4_row0_col4 {\n",
       "  background-color: #44bf70;\n",
       "  color: #f1f1f1;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_e88c4_row1_col0 {\n",
       "  background-color: #8ed645;\n",
       "  color: #000000;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_e88c4_row1_col2 {\n",
       "  background-color: #d5e21a;\n",
       "  color: #000000;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_e88c4_row1_col3, #T_e88c4_row4_col1 {\n",
       "  background-color: #f4e61e;\n",
       "  color: #000000;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_e88c4_row2_col0 {\n",
       "  background-color: #2a768e;\n",
       "  color: #f1f1f1;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_e88c4_row2_col1 {\n",
       "  background-color: #81d34d;\n",
       "  color: #000000;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_e88c4_row2_col3 {\n",
       "  background-color: #77d153;\n",
       "  color: #000000;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_e88c4_row2_col4 {\n",
       "  background-color: #22a884;\n",
       "  color: #f1f1f1;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_e88c4_row3_col0 {\n",
       "  background-color: #34608d;\n",
       "  color: #f1f1f1;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_e88c4_row3_col1 {\n",
       "  background-color: #b2dd2d;\n",
       "  color: #000000;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_e88c4_row3_col2 {\n",
       "  background-color: #482071;\n",
       "  color: #f1f1f1;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_e88c4_row3_col4 {\n",
       "  background-color: #5cc863;\n",
       "  color: #000000;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_e88c4_row5_col0 {\n",
       "  background-color: #2c728e;\n",
       "  color: #f1f1f1;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_e88c4_row5_col1 {\n",
       "  background-color: #1fa287;\n",
       "  color: #f1f1f1;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_e88c4_row5_col2 {\n",
       "  background-color: #433e85;\n",
       "  color: #f1f1f1;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_e88c4_row5_col3 {\n",
       "  background-color: #481668;\n",
       "  color: #f1f1f1;\n",
       "  font-size: 20px;\n",
       "}\n",
       "#T_e88c4_row5_col4 {\n",
       "  background-color: #32658e;\n",
       "  color: #f1f1f1;\n",
       "  font-size: 20px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e88c4_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >true_mf</th>\n",
       "      <th class=\"col_heading level0 col1\" >true_mb</th>\n",
       "      <th class=\"col_heading level0 col2\" >true_habit</th>\n",
       "      <th class=\"col_heading level0 col3\" >true_wsls</th>\n",
       "      <th class=\"col_heading level0 col4\" >true_kdh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e88c4_level0_row0\" class=\"row_heading level0 row0\" >fit_mf</th>\n",
       "      <td id=\"T_e88c4_row0_col0\" class=\"data row0 col0\" >0.493000</td>\n",
       "      <td id=\"T_e88c4_row0_col1\" class=\"data row0 col1\" >0.699000</td>\n",
       "      <td id=\"T_e88c4_row0_col2\" class=\"data row0 col2\" >0.653000</td>\n",
       "      <td id=\"T_e88c4_row0_col3\" class=\"data row0 col3\" >0.661000</td>\n",
       "      <td id=\"T_e88c4_row0_col4\" class=\"data row0 col4\" >0.623000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e88c4_level0_row1\" class=\"row_heading level0 row1\" >fit_mb</th>\n",
       "      <td id=\"T_e88c4_row1_col0\" class=\"data row1 col0\" >0.664000</td>\n",
       "      <td id=\"T_e88c4_row1_col1\" class=\"data row1 col1\" >0.588000</td>\n",
       "      <td id=\"T_e88c4_row1_col2\" class=\"data row1 col2\" >0.685000</td>\n",
       "      <td id=\"T_e88c4_row1_col3\" class=\"data row1 col3\" >0.691000</td>\n",
       "      <td id=\"T_e88c4_row1_col4\" class=\"data row1 col4\" >0.679000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e88c4_level0_row2\" class=\"row_heading level0 row2\" >fit_habit</th>\n",
       "      <td id=\"T_e88c4_row2_col0\" class=\"data row2 col0\" >0.574000</td>\n",
       "      <td id=\"T_e88c4_row2_col1\" class=\"data row2 col1\" >0.678000</td>\n",
       "      <td id=\"T_e88c4_row2_col2\" class=\"data row2 col2\" >0.411000</td>\n",
       "      <td id=\"T_e88c4_row2_col3\" class=\"data row2 col3\" >0.655000</td>\n",
       "      <td id=\"T_e88c4_row2_col4\" class=\"data row2 col4\" >0.604000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e88c4_level0_row3\" class=\"row_heading level0 row3\" >test_nlp_wsls</th>\n",
       "      <td id=\"T_e88c4_row3_col0\" class=\"data row3 col0\" >0.555000</td>\n",
       "      <td id=\"T_e88c4_row3_col1\" class=\"data row3 col1\" >0.686000</td>\n",
       "      <td id=\"T_e88c4_row3_col2\" class=\"data row3 col2\" >0.437000</td>\n",
       "      <td id=\"T_e88c4_row3_col3\" class=\"data row3 col3\" >0.503000</td>\n",
       "      <td id=\"T_e88c4_row3_col4\" class=\"data row3 col4\" >0.632000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e88c4_level0_row4\" class=\"row_heading level0 row4\" >fit_kdh</th>\n",
       "      <td id=\"T_e88c4_row4_col0\" class=\"data row4 col0\" >0.699000</td>\n",
       "      <td id=\"T_e88c4_row4_col1\" class=\"data row4 col1\" >0.697000</td>\n",
       "      <td id=\"T_e88c4_row4_col2\" class=\"data row4 col2\" >0.704000</td>\n",
       "      <td id=\"T_e88c4_row4_col3\" class=\"data row4 col3\" >0.694000</td>\n",
       "      <td id=\"T_e88c4_row4_col4\" class=\"data row4 col4\" >0.492000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e88c4_level0_row5\" class=\"row_heading level0 row5\" >fit_logistic_regression</th>\n",
       "      <td id=\"T_e88c4_row5_col0\" class=\"data row5 col0\" >0.571000</td>\n",
       "      <td id=\"T_e88c4_row5_col1\" class=\"data row5 col1\" >0.652000</td>\n",
       "      <td id=\"T_e88c4_row5_col2\" class=\"data row5 col2\" >0.464000</td>\n",
       "      <td id=\"T_e88c4_row5_col3\" class=\"data row5 col3\" >0.514000</td>\n",
       "      <td id=\"T_e88c4_row5_col4\" class=\"data row5 col4\" >0.552000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x209f9279fa0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model = ['mf','mb','habit','wsls','kdh']\n",
    "all_df = []\n",
    "for m in Model:\n",
    "    df = pd.read_csv(f'../results/{m}/{m}_fit.csv')\n",
    "    col = [name for name in df.columns if 'test_nlp' in name]\n",
    "    df = pd.DataFrame(df[col].describe().loc['mean'])\n",
    "    df.rename(columns={'mean':f'true_{m}'},inplace=True) \n",
    "    df = df.round(3)\n",
    "    all_df.append(df)\n",
    "    \n",
    "d = pd.concat(all_df, axis=1)\n",
    "\n",
    "d.rename(index={'test_nlp_mf':'fit_mf',\n",
    "                'test_nlp_mb':'fit_mb',\n",
    "                'test_nlp_habit':'fit_habit',\n",
    "                'test_nlp_lwsls':'fit_wsls',\n",
    "                'test_nlp_kdh':'fit_kdh',\n",
    "                'test_nlp_logistic_regression':'fit_logistic_regression'},inplace=True)\n",
    "lr = pd.DataFrame(d.iloc[5])\n",
    "\n",
    "d.style.background_gradient(cmap ='viridis').set_properties(**{'font-size': '20px'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
