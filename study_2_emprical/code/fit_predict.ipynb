{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805c8b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "import multiprocessing as mp\n",
    "import pickle \n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from imports import*\n",
    "from utils import *\n",
    "from logistic_regression import *\n",
    "from rnn import *\n",
    "\n",
    "from hybrid_sim import *\n",
    "from hybrid_fit import *\n",
    "from hybrid_predict import *\n",
    "\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "from scipy.stats import pearsonr , spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0603e6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tst = pd.read_csv('../data/TST.csv')\n",
    "df_iq = pd.read_csv('../data/wasi.csv')\n",
    "ids = df_iq['SubjectID'].values\n",
    "\n",
    "def update_data_frame(df): \n",
    "    # this funcation add to the data frame 3 columns:\n",
    "    # 1 - prev_reward : if the last trail was rewarded\n",
    "    # 2 - transation_prev : if the last transation was rare or common\n",
    "    # 3 - stay probs \n",
    "    df['prev_reward'] = df['reward'].shift(1,fill_value=0)\n",
    "    df['transition_prev'] = df['transition_type'].shift(1,fill_value=0)\n",
    "    df['stay'] = df['action_stage_1'].shift(1)==df['action_stage_1']\n",
    "    \n",
    "def sigmoid(x):\n",
    "    return(1.0 / (1.0 + np.exp(-x)))\n",
    "\n",
    "def inverse_sigmoid(y):\n",
    "    return(np.log(y/(1-y)))\n",
    "\n",
    "all_dfs = []\n",
    "\n",
    "for i in ids:\n",
    "    if i == 25510:\n",
    "        continue\n",
    "    df = df_tst[df_tst['subjectID'] == i]\n",
    "    df.reset_index(inplace=True)\n",
    "    all_dfs.append(df)\n",
    "\n",
    "new_all_dfs = []\n",
    "\n",
    "for i in all_dfs:\n",
    "    if i.shape[0] == 443: # 121 322 443\n",
    "        new_all_dfs.append(i)\n",
    "        \n",
    "block_0 = []\n",
    "\n",
    "for i in new_all_dfs:\n",
    "    df = i[i['measurement'] == 'baseline']\n",
    "    df.reset_index(inplace=True)\n",
    "    block_0.append(df)\n",
    "\n",
    "block_1 = []\n",
    "\n",
    "for i in new_all_dfs:\n",
    "    df = i[i['measurement'] == 'followup']\n",
    "    df.reset_index(inplace=True)\n",
    "    block_1.append(df)\n",
    "\n",
    "block_2 = []\n",
    "\n",
    "for i in new_all_dfs:\n",
    "    df = i[i['measurement'] == 'six_month']\n",
    "    df.reset_index(inplace=True)\n",
    "    block_2.append(df)\n",
    "    \n",
    "ids = []\n",
    "for i in block_0:\n",
    "    ids.append(i['subjectID'].unique()[0])\n",
    "\n",
    "IQs = []\n",
    "for i in ids:\n",
    "    IQs.append(df_iq[df_iq['SubjectID'] == i].IQ.values[0])\n",
    "    \n",
    "for df_i in block_0:\n",
    "    df_i.rename(columns=\n",
    "                    {\n",
    "                    'choice1':'action_stage_1',\n",
    "                    'choice2':'action_stage_2',\n",
    "                    '2nd_stage_state':'state_of_stage_2',\n",
    "                    'transition':'transition_type',\n",
    "                    'reward':'reward'},inplace=True\n",
    "                    )\n",
    "    \n",
    "    df_i.drop(columns={\n",
    "        'level_0', 'index','measurement','key1', 'key2','rt1', 'rt2',\n",
    "       'iti','1st_stage_stim_left', '1st_stage_stim_right',\n",
    "       '2nd_stage_stim_left', '2nd_stage_stim_right',\n",
    "         'p1','p2', 'p3', 'p4'},inplace=True)\n",
    "    \n",
    "    df_i['action_stage_1']-=1\n",
    "    df_i['action_stage_2']%=2\n",
    "    df_i['state_of_stage_2']-=1\n",
    "    update_data_frame(df_i)\n",
    "    df_i.dropna(inplace=True)\n",
    "    \n",
    "for df_i in block_1:\n",
    "    df_i.rename(columns=\n",
    "                    {\n",
    "                    'choice1':'action_stage_1',\n",
    "                    'choice2':'action_stage_2',\n",
    "                    '2nd_stage_state':'state_of_stage_2',\n",
    "                    'transition':'transition_type',\n",
    "                    'reward':'reward'},inplace=True\n",
    "                    )\n",
    "    \n",
    "    df_i.drop(columns={\n",
    "        'level_0', 'index','measurement','key1', 'key2','rt1', 'rt2',\n",
    "       'iti','1st_stage_stim_left', '1st_stage_stim_right',\n",
    "       '2nd_stage_stim_left', '2nd_stage_stim_right',\n",
    "         'p1','p2', 'p3', 'p4'},inplace=True)\n",
    "    \n",
    "    df_i['action_stage_1']-=1\n",
    "    df_i['action_stage_2']%=2\n",
    "    df_i['state_of_stage_2']-=1\n",
    "    update_data_frame(df_i)\n",
    "    df_i.dropna(inplace=True)\n",
    "    \n",
    "\n",
    "for df_i in block_2:\n",
    "    df_i.rename(columns=\n",
    "                    {\n",
    "                    'choice1':'action_stage_1',\n",
    "                    'choice2':'action_stage_2',\n",
    "                    '2nd_stage_state':'state_of_stage_2',\n",
    "                    'transition':'transition_type',\n",
    "                    'reward':'reward'},inplace=True\n",
    "                    )\n",
    "    \n",
    "    df_i.drop(columns={\n",
    "        'level_0', 'index','measurement','key1', 'key2','rt1', 'rt2',\n",
    "       'iti','1st_stage_stim_left', '1st_stage_stim_right',\n",
    "       '2nd_stage_stim_left', '2nd_stage_stim_right',\n",
    "         'p1','p2', 'p3', 'p4'},inplace=True)\n",
    "    \n",
    "    df_i['action_stage_1']-=1\n",
    "    df_i['action_stage_2']%=2\n",
    "    df_i['state_of_stage_2']-=1\n",
    "    update_data_frame(df_i)\n",
    "    df_i.dropna(inplace=True)\n",
    "    \n",
    "    \n",
    "all_blocks = [block_0,block_1,block_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4a4df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num of agent\n",
    "num_of_agents = len(all_blocks[0])\n",
    "\n",
    "# num of block\n",
    "num_of_block = 3\n",
    "\n",
    "# for cross valdation \n",
    "array = np.arange(num_of_block)\n",
    "cv = [np.roll(array,i) for i in range(num_of_block)]\n",
    "cv = np.array(cv)\n",
    "\n",
    "models = {\n",
    "\n",
    "    'hybrid':[ configuration_parameters_hybrid,\n",
    "               hybrid_sim,\n",
    "               hybrid_fit,\n",
    "               hybrid_predict],\n",
    "    \n",
    "\n",
    "}\n",
    "\n",
    "def bce(y_hat,y_true):\n",
    "    eps = 1e-7\n",
    "    return -np.sum( y_true*np.log(y_hat+eps) + (1-y_true)*np.log(1-y_hat+eps) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e1e185",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_results = {\n",
    "    \n",
    "   'agent': [],\n",
    "   'train_block': [],\n",
    "    \n",
    "   'train_nll_hybrid' : [],\n",
    "   'val_nll_hybrid' : [],\n",
    "   'test_nll_hybrid': [], \n",
    "\n",
    "    \n",
    "}\n",
    "\n",
    "K = 5\n",
    "N = num_of_agents\n",
    "data_results['agent'].append(np.tile(np.arange(0,N),len(cv)))\n",
    "data_results['train_block'].append(np.repeat(cv[:,0],N))\n",
    "\n",
    "for m in tqdm(models): \n",
    "\n",
    "    print(f'*** Fit with {m} ***')\n",
    "    \n",
    "    for train, val, test in cv:\n",
    "        print(f'*** train {train} | val {val} | test {test} ***')\n",
    "        \n",
    "        # fit k times \n",
    "        fit_res = []\n",
    "        for _ in range(K):\n",
    "            pool = mp.Pool(processes=mp.cpu_count())\n",
    "            fit = pool.map(models[m][2], all_blocks[train])\n",
    "            pool.close()\n",
    "            fit_res.append(fit)\n",
    "            \n",
    "        # best train/validation nll    \n",
    "        all_nll_train = np.zeros(shape=(K,N))\n",
    "        all_nll_val = np.zeros(shape=(K,N))\n",
    "        all_nll_test = np.zeros(shape=(K,N))\n",
    "        best_parameters = [] \n",
    "        for k in range(K):\n",
    "            for n in range(N):\n",
    "                _ , y_hat, _ = models[m][3](all_blocks[train][n], fit_res[k][n].x)\n",
    "                nLL = bce(1-y_hat, all_blocks[train][n]['action_stage_1'].values)\n",
    "                all_nll_train[k,n] =  nLL\n",
    "                \n",
    "                _ , y_hat, _ = models[m][3](all_blocks[val][n], fit_res[k][n].x)\n",
    "                nLL = bce(1-y_hat, all_blocks[val][n]['action_stage_1'].values)\n",
    "                all_nll_val[k,n] = nLL\n",
    "                \n",
    "                _ , y_hat, _ = models[m][3](all_blocks[test][n], fit_res[k][n].x)\n",
    "                nLL = bce(1-y_hat, all_blocks[test][n]['action_stage_1'].values)\n",
    "                all_nll_test[k,n] = nLL\n",
    "                \n",
    "        best_train = all_nll_train.min(axis=0)\n",
    "        best_val = all_nll_val.min(axis=0)\n",
    "        indx = np.argmin(all_nll_val,axis=0)\n",
    "        best_test = np.array([all_nll_test[indx[n],n] for n in range(N)])\n",
    "\n",
    "        data_results[f'train_nll_{m}'].append(best_train)\n",
    "        data_results[f'val_nll_{m}'].append(best_val)\n",
    "        data_results[f'test_nll_{m}'].append(best_test)\n",
    "        \n",
    "\n",
    "for k in data_results:\n",
    "    data_results[k] = np.concatenate(data_results[k])\n",
    "df_the = pd.DataFrame(data_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d252314",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 1\n",
    "N = num_of_agents # 3 models\n",
    "\n",
    "data_results_lr = {\n",
    "        \n",
    "   'train_nll_lr' : [],\n",
    "   'val_nll_lr' : [],\n",
    "   'test_nll_lr': [], \n",
    "    \n",
    "}\n",
    "\n",
    "for train, val, test in cv:\n",
    "    print(f'*** train {train} | val {val} | test {test} ***')\n",
    "    \n",
    "    all_nll_train = np.zeros(shape=(K,N))\n",
    "    all_nll_val = np.zeros(shape=(K,N))\n",
    "    all_nll_test = np.zeros(shape=(K,N))\n",
    "    \n",
    "    fit_res = []    \n",
    "    for k in range(K):\n",
    "        cur_res = []\n",
    "        for n in range(N):\n",
    "            X, y = preprocess_logistic_regression(all_blocks[train][n],lag=k+1)\n",
    "            clf, inter, coef = fit_logistic_regression(X,y)\n",
    "            cur_res.append(clf)\n",
    "        fit_res.append(cur_res)\n",
    "            \n",
    "    # best train/validation nll    \n",
    "    for k in range(K):\n",
    "        for n in range(N):\n",
    "            clf = fit_res[k][n]\n",
    "            \n",
    "            # train\n",
    "            X, y = preprocess_logistic_regression(all_blocks[train][n],lag=k+1)\n",
    "            if clf == None:\n",
    "                nLL = -np.log(.5)*200\n",
    "            else:\n",
    "                y_hat = clf.predict_proba(X)[:,0]\n",
    "                nLL = bce(1-y_hat, all_blocks[train][n]['action_stage_1'].values)\n",
    "            \n",
    "            all_nll_train[k,n] = nLL\n",
    "            \n",
    "            # validation\n",
    "            X, y = preprocess_logistic_regression(all_blocks[val][n],lag=k+1)\n",
    "            if clf == None:\n",
    "                nLL = -np.log(.5)*200\n",
    "            else:\n",
    "                y_hat = clf.predict_proba(X)[:,0]\n",
    "                nLL = bce(1-y_hat, all_blocks[val][n]['action_stage_1'].values)\n",
    "            \n",
    "            all_nll_val[k,n] = nLL\n",
    "\n",
    "            X, y = preprocess_logistic_regression(all_blocks[test][n],lag=k+1)            \n",
    "            if clf == None:\n",
    "                nLL = -np.log(.5)*200\n",
    "            else:\n",
    "                y_hat = clf.predict_proba(X)[:,0]\n",
    "                nLL = bce(1-y_hat, all_blocks[test][n]['action_stage_1'].values)\n",
    "                \n",
    "            all_nll_test[k,n] = nLL\n",
    "            \n",
    "    best_train = all_nll_train.min(axis=0)\n",
    "    best_val = all_nll_val.min(axis=0)\n",
    "    indx = np.argmin(all_nll_val,axis=0)\n",
    "    best_test = np.array([all_nll_test[indx[n],n] for n in range(N)])\n",
    "    \n",
    "    data_results_lr[f'train_nll_lr'].append(best_train)\n",
    "    data_results_lr[f'val_nll_lr'].append(best_val)\n",
    "    data_results_lr[f'test_nll_lr'].append(best_test)\n",
    "    \n",
    "for k in data_results_lr:\n",
    "    data_results_lr[k] = np.concatenate(data_results_lr[k])\n",
    "df_lr = pd.DataFrame(data_results_lr)\n",
    "\n",
    "\n",
    "df = pd.concat([df_the,df_lr],axis=1)\n",
    "df.to_csv('../results/hybrid7_lr1_emp.csv')\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e649eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = num_of_agents # 3 models\n",
    "\n",
    "INPUT_SIZE = 5\n",
    "OUTPUT_SIZE = 2\n",
    "LERANING_RATE = 0.001\n",
    "\n",
    "hidden_size = 5\n",
    "num_layers = 1\n",
    "epochs = 1000\n",
    "\n",
    "loss_train, loss_val, loss_test  = [], [], []\n",
    "ll_train, ll_val, ll_test = [], [], []\n",
    "\n",
    "for n in tqdm(range(N)):\n",
    "    for train, val, test in cv:\n",
    "\n",
    "        train_data = behavior_dataset(all_blocks[train][n])\n",
    "        val_data = behavior_dataset(all_blocks[val][n])\n",
    "        test_data = behavior_dataset(all_blocks[test][n])\n",
    "\n",
    "        train_loader = DataLoader(train_data,shuffle=False,batch_size=len(train_data))\n",
    "        val_loader = DataLoader(val_data,shuffle=False,batch_size=len(val_data))\n",
    "        test_loader = DataLoader(test_data,shuffle=False,batch_size=len(test_data))\n",
    "        \n",
    "        rnn = GRU_NN(INPUT_SIZE, hidden_size, num_layers, OUTPUT_SIZE)\n",
    "        rnn, train_loss, train_ll, val_loss, val_ll, test_loss, test_ll = train_model(rnn,\n",
    "                                                                                train_loader,\n",
    "                                                                                val_loader,\n",
    "                                                                                test_loader,\n",
    "                                                                                epochs=epochs,\n",
    "                                                                                lr=LERANING_RATE) \n",
    "                                                                                                                                       \n",
    "        loss_train.append(train_loss)\n",
    "        loss_val.append(val_loss)\n",
    "        loss_test.append(test_loss)\n",
    "        \n",
    "        ll_train.append(train_ll)\n",
    "        ll_val.append(val_ll)\n",
    "        ll_test.append(test_ll)\n",
    "        \n",
    "    print('Done agent',n)\n",
    "    \n",
    "    \n",
    "with open('../results/loss_train.pickle', 'wb') as handle:\n",
    "    pickle.dump(loss_train, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('../results/loss_val.pickle', 'wb') as handle:\n",
    "    pickle.dump(loss_val, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('../results/loss_test.pickle', 'wb') as handle:\n",
    "    pickle.dump(loss_test, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('../results/ll_train.pickle', 'wb') as handle:\n",
    "    pickle.dump(ll_train, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('../results/ll_val.pickle', 'wb') as handle:\n",
    "    pickle.dump(ll_val, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('../results/ll_test.pickle', 'wb') as handle:\n",
    "    pickle.dump(ll_test, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
