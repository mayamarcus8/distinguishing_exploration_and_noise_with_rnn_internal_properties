{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805c8b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns \n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr, ttest_rel\n",
    "\n",
    "import multiprocessing as mp\n",
    "import pickle \n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from imports import*\n",
    "from utils import *\n",
    "from logistic_regression import *\n",
    "from rnn import *\n",
    "\n",
    "from hybrid_sim import *\n",
    "from hybrid_fit import *\n",
    "from hybrid_predict import *\n",
    "\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4540e878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df_tst = pd.read_csv('../data/TST.csv')\n",
    "df_iq = pd.read_csv('../data/wasi.csv')\n",
    "ids = df_iq['SubjectID'].values\n",
    "\n",
    "def update_data_frame(df): \n",
    "    # this funcation add to the data frame 3 columns:\n",
    "    # 1 - prev_reward : if the last trail was rewarded\n",
    "    # 2 - transation_prev : if the last transation was rare or common\n",
    "    # 3 - stay probs \n",
    "    df['prev_reward'] = df['reward'].shift(1,fill_value=0)\n",
    "    df['transition_prev'] = df['transition_type'].shift(1,fill_value=0)\n",
    "    df['stay'] = (df['action_stage_1'].shift(1)==df['action_stage_1']).astype(int)\n",
    "    \n",
    "def sigmoid(x):\n",
    "    return(1.0 / (1.0 + np.exp(-x)))\n",
    "\n",
    "def inverse_sigmoid(y):\n",
    "    return(np.log(y/(1-y)))\n",
    "\n",
    "all_dfs = []\n",
    "\n",
    "for i in ids:\n",
    "    if i == 25510:\n",
    "        continue\n",
    "    df = df_tst[df_tst['subjectID'] == i]\n",
    "    df.reset_index(inplace=True)\n",
    "    all_dfs.append(df)\n",
    "\n",
    "new_all_dfs = []\n",
    "\n",
    "for i in all_dfs:\n",
    "    if i.shape[0] == 322:\n",
    "        new_all_dfs.append(i)\n",
    "        \n",
    "block_0 = []\n",
    "\n",
    "for i in new_all_dfs:\n",
    "    df = i[i['measurement'] == 'baseline']\n",
    "    df.reset_index(inplace=True)\n",
    "    block_0.append(df)\n",
    "\n",
    "block_1 = []\n",
    "\n",
    "for i in new_all_dfs:\n",
    "    df = i[i['measurement'] == 'followup']\n",
    "    df.reset_index(inplace=True)\n",
    "    block_1.append(df)\n",
    "    \n",
    "ids = []\n",
    "for i in block_0:\n",
    "    ids.append(i['subjectID'].unique()[0])\n",
    "\n",
    "IQs = []\n",
    "for i in ids:\n",
    "    IQs.append(df_iq[df_iq['SubjectID'] == i].IQ.values[0])\n",
    "    \n",
    "for df_i in block_0:\n",
    "    df_i.rename(columns=\n",
    "                    {\n",
    "                    'choice1':'action_stage_1',\n",
    "                    'choice2':'action_stage_2',\n",
    "                    '2nd_stage_state':'state_of_stage_2',\n",
    "                    'transition':'transition_type',\n",
    "                    'reward':'reward'},inplace=True\n",
    "                    )\n",
    "    \n",
    "    df_i.drop(columns={\n",
    "        'level_0', 'index','measurement','key1', 'key2','rt1', 'rt2',\n",
    "       'iti','1st_stage_stim_left', '1st_stage_stim_right',\n",
    "       '2nd_stage_stim_left', '2nd_stage_stim_right',\n",
    "         'p1','p2', 'p3', 'p4'},inplace=True)\n",
    "    \n",
    "    df_i['action_stage_1']-=1\n",
    "    df_i['action_stage_2']%=2\n",
    "    df_i['state_of_stage_2']-=1\n",
    "    update_data_frame(df_i)\n",
    "    df_i.dropna(inplace=True)\n",
    "    \n",
    "for df_i in block_1:\n",
    "    df_i.rename(columns=\n",
    "                    {\n",
    "                    'choice1':'action_stage_1',\n",
    "                    'choice2':'action_stage_2',\n",
    "                    '2nd_stage_state':'state_of_stage_2',\n",
    "                    'transition':'transition_type',\n",
    "                    'reward':'reward'},inplace=True\n",
    "                    )\n",
    "    \n",
    "    df_i.drop(columns={\n",
    "        'level_0', 'index','measurement','key1', 'key2','rt1', 'rt2',\n",
    "       'iti','1st_stage_stim_left', '1st_stage_stim_right',\n",
    "       '2nd_stage_stim_left', '2nd_stage_stim_right',\n",
    "         'p1','p2', 'p3', 'p4'},inplace=True)\n",
    "    \n",
    "    df_i['action_stage_1']-=1\n",
    "    df_i['action_stage_2']%=2\n",
    "    df_i['state_of_stage_2']-=1\n",
    "    update_data_frame(df_i)\n",
    "    df_i.dropna(inplace=True)\n",
    "    \n",
    "sns.displot(np.array(IQs))\n",
    "print('mean',np.array(IQs).mean())\n",
    "print('std',np.array(IQs).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf08582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_pre(net, train_loader, val_loader , epochs, lr):\n",
    "    \n",
    "    min_loss_v = 1000\n",
    "        \n",
    "    train_loss, train_ll = np.zeros(epochs), np.zeros(epochs)\n",
    "    val_loss ,val_ll = np.zeros(epochs), np.zeros(epochs)\n",
    "\n",
    "    # move net to GPU\n",
    "    net.to(device)\n",
    "    # Use Adam optimizer\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr) \n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    # Loop over epochs\n",
    "    for i in tqdm(range(epochs)):\n",
    "        \n",
    "        # Loop over training batches\n",
    "        running_loss_tr = []\n",
    "        for j,(X_train,y_train) in enumerate(train_loader):\n",
    "            \n",
    "            # move to GPU\n",
    "            X_train , y_train = X_train.to(device), y_train.to(device)\n",
    "            # reshape to 1 X batch_size X input_size\n",
    "            X_train = X_train.reshape(1,X_train.shape[0], INPUT_SIZE)\n",
    "            # zero the gradient buffers\n",
    "            optimizer.zero_grad() \n",
    "            out, hn = net(X_train)\n",
    "            # Reshape to (SeqLen x Batch, OutputSize)\n",
    "            out = out.view(-1, OUTPUT_SIZE)\n",
    "            loss = criterion(out, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step() # Does the update\n",
    "            running_loss_tr.append(loss.item())\n",
    "            \n",
    "        train_loss[i], train_ll[i] = eval_net(net, train_loader)\n",
    "        val_loss[i], val_ll[i] = eval_net(net, val_loader)\n",
    "        \n",
    "        if val_loss[i] <= min_loss_v:\n",
    "            checkpoint = {'epoch':i+1,'model_state':net.state_dict(),\n",
    "                          'optim_state':optimizer.state_dict(),'loss':val_loss[i]}\n",
    "            torch.save(checkpoint,f'rnn_finetune_5.pth')\n",
    "            min_loss_v = val_loss[i]\n",
    "        \n",
    "        print('train loss: ', train_loss[i])\n",
    "        print('val loss: ',val_loss[i])\n",
    "        net.train()\n",
    "\n",
    "    return net, train_loss , train_ll , val_loss, val_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f907acd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat(block_1).reset_index()\n",
    "df_val = pd.concat(block_0).reset_index()\n",
    "\n",
    "INPUT_SIZE = 5\n",
    "OUTPUT_SIZE = 2\n",
    "LERANING_RATE = 0.001\n",
    "\n",
    "hidden_size = 5\n",
    "num_layers = 1\n",
    "epochs = 500\n",
    "\n",
    "\n",
    "train_data = behavior_dataset(df_train)\n",
    "val_data = behavior_dataset(df_val)\n",
    "\n",
    "train_loader = DataLoader(train_data,shuffle=False,batch_size=1000)\n",
    "val_loader = DataLoader(val_data,shuffle=False,batch_size=1000)\n",
    "\n",
    "rnn = GRU_NN(INPUT_SIZE, hidden_size, num_layers, OUTPUT_SIZE)\n",
    "rnn, train_loss, train_ll, val_loss, val_ll, = train_model_pre(rnn,\n",
    "                                                            train_loader,\n",
    "                                                            val_loader,\n",
    "                                                            epochs=epochs,\n",
    "                                                            lr=LERANING_RATE) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0603e6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df_tst = pd.read_csv('../data/TST.csv')\n",
    "df_iq = pd.read_csv('../data/wasi.csv')\n",
    "ids = df_iq['SubjectID'].values\n",
    "\n",
    "def update_data_frame(df): \n",
    "    # this funcation add to the data frame 3 columns:\n",
    "    # 1 - prev_reward : if the last trail was rewarded\n",
    "    # 2 - transation_prev : if the last transation was rare or common\n",
    "    # 3 - stay probs \n",
    "    df['prev_reward'] = df['reward'].shift(1,fill_value=0)\n",
    "    df['transition_prev'] = df['transition_type'].shift(1,fill_value=0)\n",
    "    df['stay'] = df['action_stage_1'].shift(1)==df['action_stage_1']\n",
    "    \n",
    "def sigmoid(x):\n",
    "    return(1.0 / (1.0 + np.exp(-x)))\n",
    "\n",
    "def inverse_sigmoid(y):\n",
    "    return(np.log(y/(1-y)))\n",
    "\n",
    "all_dfs = []\n",
    "\n",
    "for i in ids:\n",
    "    if i == 25510:\n",
    "        continue\n",
    "    df = df_tst[df_tst['subjectID'] == i]\n",
    "    df.reset_index(inplace=True)\n",
    "    all_dfs.append(df)\n",
    "\n",
    "new_all_dfs = []\n",
    "\n",
    "for i in all_dfs:\n",
    "    if i.shape[0] == 443: # 121 322 443\n",
    "        new_all_dfs.append(i)\n",
    "        \n",
    "block_00 = []\n",
    "\n",
    "for i in new_all_dfs:\n",
    "    df = i[i['measurement'] == 'baseline']\n",
    "    df.reset_index(inplace=True)\n",
    "    block_00.append(df)\n",
    "\n",
    "block_11 = []\n",
    "\n",
    "for i in new_all_dfs:\n",
    "    df = i[i['measurement'] == 'followup']\n",
    "    df.reset_index(inplace=True)\n",
    "    block_11.append(df)\n",
    "\n",
    "block_22 = []\n",
    "\n",
    "for i in new_all_dfs:\n",
    "    df = i[i['measurement'] == 'six_month']\n",
    "    df.reset_index(inplace=True)\n",
    "    block_22.append(df)\n",
    "    \n",
    "ids = []\n",
    "for i in block_00:\n",
    "    ids.append(i['subjectID'].unique()[0])\n",
    "\n",
    "IQs_2 = []\n",
    "for i in ids:\n",
    "    IQs_2.append(df_iq[df_iq['SubjectID'] == i].IQ.values[0])\n",
    "    \n",
    "for df_i in block_00:\n",
    "    df_i.rename(columns=\n",
    "                    {\n",
    "                    'choice1':'action_stage_1',\n",
    "                    'choice2':'action_stage_2',\n",
    "                    '2nd_stage_state':'state_of_stage_2',\n",
    "                    'transition':'transition_type',\n",
    "                    'reward':'reward'},inplace=True\n",
    "                    )\n",
    "    \n",
    "    df_i.drop(columns={\n",
    "        'level_0', 'index','measurement','key1', 'key2','rt1', 'rt2',\n",
    "       'iti','1st_stage_stim_left', '1st_stage_stim_right',\n",
    "       '2nd_stage_stim_left', '2nd_stage_stim_right',\n",
    "         'p1','p2', 'p3', 'p4'},inplace=True)\n",
    "    \n",
    "    df_i['action_stage_1']-=1\n",
    "    df_i['action_stage_2']%=2\n",
    "    df_i['state_of_stage_2']-=1\n",
    "    update_data_frame(df_i)\n",
    "    df_i.dropna(inplace=True)\n",
    "    \n",
    "for df_i in block_11:\n",
    "    df_i.rename(columns=\n",
    "                    {\n",
    "                    'choice1':'action_stage_1',\n",
    "                    'choice2':'action_stage_2',\n",
    "                    '2nd_stage_state':'state_of_stage_2',\n",
    "                    'transition':'transition_type',\n",
    "                    'reward':'reward'},inplace=True\n",
    "                    )\n",
    "    \n",
    "    df_i.drop(columns={\n",
    "        'level_0', 'index','measurement','key1', 'key2','rt1', 'rt2',\n",
    "       'iti','1st_stage_stim_left', '1st_stage_stim_right',\n",
    "       '2nd_stage_stim_left', '2nd_stage_stim_right',\n",
    "         'p1','p2', 'p3', 'p4'},inplace=True)\n",
    "    \n",
    "    df_i['action_stage_1']-=1\n",
    "    df_i['action_stage_2']%=2\n",
    "    df_i['state_of_stage_2']-=1\n",
    "    update_data_frame(df_i)\n",
    "    df_i.dropna(inplace=True)\n",
    "    \n",
    "\n",
    "for df_i in block_22:\n",
    "    df_i.rename(columns=\n",
    "                    {\n",
    "                    'choice1':'action_stage_1',\n",
    "                    'choice2':'action_stage_2',\n",
    "                    '2nd_stage_state':'state_of_stage_2',\n",
    "                    'transition':'transition_type',\n",
    "                    'reward':'reward'},inplace=True\n",
    "                    )\n",
    "    \n",
    "    df_i.drop(columns={\n",
    "        'level_0', 'index','measurement','key1', 'key2','rt1', 'rt2',\n",
    "       'iti','1st_stage_stim_left', '1st_stage_stim_right',\n",
    "       '2nd_stage_stim_left', '2nd_stage_stim_right',\n",
    "         'p1','p2', 'p3', 'p4'},inplace=True)\n",
    "    \n",
    "    df_i['action_stage_1']-=1\n",
    "    df_i['action_stage_2']%=2\n",
    "    df_i['state_of_stage_2']-=1\n",
    "    update_data_frame(df_i)\n",
    "    df_i.dropna(inplace=True)\n",
    "    \n",
    "all_blocks = [block_00,block_11,block_22] \n",
    "\n",
    "sns.displot(np.array(IQs_2))\n",
    "print('mean',np.array(IQs_2).mean())\n",
    "print('std',np.array(IQs_2).std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e649eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num of agent\n",
    "N = len(all_blocks[0])\n",
    "\n",
    "# num of block\n",
    "num_of_block = 3\n",
    "\n",
    "# for cross valdation \n",
    "array = np.arange(num_of_block)\n",
    "cv = [np.roll(array,i) for i in range(num_of_block)]\n",
    "cv = np.array(cv)\n",
    "\n",
    "\n",
    "INPUT_SIZE = 5\n",
    "OUTPUT_SIZE = 2\n",
    "LERANING_RATE = 0.001\n",
    "\n",
    "hidden_size = 5\n",
    "num_layers = 1\n",
    "epochs = 100\n",
    "\n",
    "loss_train, loss_val, loss_test  = [], [], []\n",
    "ll_train, ll_val, ll_test = [], [], []\n",
    "\n",
    "for n in tqdm(range(N)):\n",
    "    for train, val, test in cv:\n",
    "\n",
    "        train_data = behavior_dataset(all_blocks[train][n])\n",
    "        val_data = behavior_dataset(all_blocks[val][n])\n",
    "        test_data = behavior_dataset(all_blocks[test][n])\n",
    "\n",
    "        train_loader = DataLoader(train_data,shuffle=False,batch_size=len(train_data))\n",
    "        val_loader = DataLoader(val_data,shuffle=False,batch_size=len(val_data))\n",
    "        test_loader = DataLoader(test_data,shuffle=False,batch_size=len(test_data))\n",
    "        \n",
    "        load = torch.load(f'rnn_finetune_5.pth')\n",
    "        model = GRU_NN(INPUT_SIZE, hidden_size, num_layers, OUTPUT_SIZE)\n",
    "        model.load_state_dict(load['model_state'])\n",
    "        \n",
    "        _, train_loss, train_ll, val_loss, val_ll, test_loss, test_ll = train_model(model,\n",
    "                                                                                train_loader,\n",
    "                                                                                val_loader,\n",
    "                                                                                test_loader,\n",
    "                                                                                epochs=epochs,\n",
    "                                                                                lr=LERANING_RATE) \n",
    "                                                                                                                                       \n",
    "        loss_train.append(train_loss)\n",
    "        loss_val.append(val_loss)\n",
    "        loss_test.append(test_loss)\n",
    "        \n",
    "        ll_train.append(train_ll)\n",
    "        ll_val.append(val_ll)\n",
    "        ll_test.append(test_ll)\n",
    "        \n",
    "    print('Done agent',n)\n",
    "    \n",
    "    \n",
    "with open('../results_finetune/loss_train.pickle', 'wb') as handle:\n",
    "    pickle.dump(loss_train, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('../results_finetune/loss_val.pickle', 'wb') as handle:\n",
    "    pickle.dump(loss_val, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('../results_finetune/loss_test.pickle', 'wb') as handle:\n",
    "    pickle.dump(loss_test, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('../results_finetune/ll_train.pickle', 'wb') as handle:\n",
    "    pickle.dump(ll_train, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('../results_finetune/ll_val.pickle', 'wb') as handle:\n",
    "    pickle.dump(ll_val, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('../results_finetune/ll_test.pickle', 'wb') as handle:\n",
    "    pickle.dump(ll_test, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
